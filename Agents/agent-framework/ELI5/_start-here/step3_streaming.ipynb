{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step3_streaming.py - ELI5 Walkthrough\n",
    "This notebook expands `python/samples/getting_started/workflows/_start-here/step3_streaming.py` with commentary and runnable cells.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big Picture\n",
    "A Writer agent generates content, a Reviewer agent finalizes it, and `run_stream()` lets you watch every workflow event as it happens.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Ingredients\n",
    "- Custom executor classes that wrap `ChatAgent` instances.\n",
    "- Typed `WorkflowContext` usage for both sending messages and yielding outputs.\n",
    "- Streaming event loop that prints status transitions, outputs, and failures.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Imports and scenario overview\n",
    "We pull in Agent Framework streaming primitives, configure the environment, and capture the docstring that outlines the streaming workflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nStep 3: Agents in a workflow with streaming\\n\\nA Writer agent generates content,\\nthen passes the conversation to a Reviewer agent that finalizes the result.\\nThe workflow is invoked with run_stream so you can observe events as they occur.\\n\\nPurpose:\\nShow how to wrap chat agents created by AzureOpenAIChatClient inside workflow executors, wire them with WorkflowBuilder,\\nand consume streaming events from the workflow. Demonstrate the @handler pattern with typed inputs and typed\\nWorkflowContext[T_Out, T_W_Out] outputs. Agents automatically yield outputs when they complete.\\nThe streaming loop also surfaces WorkflowEvent.origin so you can distinguish runner-generated lifecycle events\\nfrom executor-generated data-plane events.\\n\\nPrerequisites:\\n- Azure OpenAI configured for AzureOpenAIChatClient with required environment variables.\\n- Authentication via azure-identity. Use AzureCliCredential and run az login before executing the sample.\\n- Basic familiarity with WorkflowBuilder, executors, edges, events, and streaming runs.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copyright (c) Microsoft. All rights reserved.\n",
    "\n",
    "import asyncio\n",
    "\n",
    "from agent_framework import (\n",
    "    ChatAgent,\n",
    "    ChatMessage,\n",
    "    Executor,\n",
    "    ExecutorFailedEvent,\n",
    "    WorkflowBuilder,\n",
    "    WorkflowContext,\n",
    "    WorkflowFailedEvent,\n",
    "    WorkflowRunState,\n",
    "    WorkflowStatusEvent,\n",
    "    handler,\n",
    ")\n",
    "from agent_framework._workflows._events import WorkflowOutputEvent\n",
    "from agent_framework.azure import AzureOpenAIChatClient\n",
    "from azure.identity import AzureCliCredential\n",
    "from typing_extensions import Never\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\"\"\"\n",
    "Step 3: Agents in a workflow with streaming\n",
    "\n",
    "A Writer agent generates content,\n",
    "then passes the conversation to a Reviewer agent that finalizes the result.\n",
    "The workflow is invoked with run_stream so you can observe events as they occur.\n",
    "\n",
    "Purpose:\n",
    "Show how to wrap chat agents created by AzureOpenAIChatClient inside workflow executors, wire them with WorkflowBuilder,\n",
    "and consume streaming events from the workflow. Demonstrate the @handler pattern with typed inputs and typed\n",
    "WorkflowContext[T_Out, T_W_Out] outputs. Agents automatically yield outputs when they complete.\n",
    "The streaming loop also surfaces WorkflowEvent.origin so you can distinguish runner-generated lifecycle events\n",
    "from executor-generated data-plane events.\n",
    "\n",
    "Prerequisites:\n",
    "- Azure OpenAI configured for AzureOpenAIChatClient with required environment variables.\n",
    "- Authentication via azure-identity. Use AzureCliCredential and run az login before executing the sample.\n",
    "- Basic familiarity with WorkflowBuilder, executors, edges, events, and streaming runs.\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Writer executor wraps a chat agent\n",
    "`Writer` seeds a conversation with the incoming `ChatMessage`, runs its agent, and forwards the growing transcript downstream.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Writer(Executor):\n",
    "    \"\"\"Custom executor that owns a domain specific agent for content generation.\n",
    "\n",
    "    This class demonstrates:\n",
    "    - Attaching a ChatAgent to an Executor so it participates as a node in a workflow.\n",
    "    - Using a @handler method to accept a typed input and forward a typed output via ctx.send_message.\n",
    "    \"\"\"\n",
    "\n",
    "    agent: ChatAgent\n",
    "\n",
    "    def __init__(self, chat_client: AzureOpenAIChatClient, id: str = \"writer\"):\n",
    "        # Create a domain specific agent using your configured AzureOpenAIChatClient.\n",
    "        self.agent = chat_client.create_agent(\n",
    "            instructions=(\n",
    "                \"You are an excellent content writer. You create new content and edit contents based on the feedback.\"\n",
    "            ),\n",
    "        )\n",
    "        # Associate this agent with the executor node. The base Executor stores it on self.agent.\n",
    "        super().__init__(id=id)\n",
    "\n",
    "    @handler\n",
    "    async def handle(self, message: ChatMessage, ctx: WorkflowContext[list[ChatMessage]]) -> None:\n",
    "        \"\"\"Generate content and forward the updated conversation.\n",
    "\n",
    "        Contract for this handler:\n",
    "        - message is the inbound user ChatMessage.\n",
    "        - ctx is a WorkflowContext that expects a list[ChatMessage] to be sent downstream.\n",
    "\n",
    "        Pattern shown here:\n",
    "        1) Seed the conversation with the inbound message.\n",
    "        2) Run the attached agent to produce assistant messages.\n",
    "        3) Forward the cumulative messages to the next executor with ctx.send_message.\n",
    "        \"\"\"\n",
    "        # Start the conversation with the incoming user message.\n",
    "        messages: list[ChatMessage] = [message]\n",
    "        # Run the agent and extend the conversation with the agent's messages.\n",
    "        response = await self.agent.run(messages)\n",
    "        messages.extend(response.messages)\n",
    "        # Forward the accumulated messages to the next executor in the workflow.\n",
    "        await ctx.send_message(messages)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Reviewer executor finalizes the response\n",
    "`Reviewer` consumes all messages, runs its agent, and yields the final text as workflow output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reviewer(Executor):\n",
    "    \"\"\"Custom executor that owns a review agent and completes the workflow.\"\"\"\n",
    "\n",
    "    agent: ChatAgent\n",
    "\n",
    "    def __init__(self, chat_client: AzureOpenAIChatClient, id: str = \"reviewer\"):\n",
    "        # Create a domain specific agent that evaluates and refines content.\n",
    "        self.agent = chat_client.create_agent(\n",
    "            instructions=(\n",
    "                \"You are an excellent content reviewer. You review the content and provide feedback to the writer.\"\n",
    "            ),\n",
    "        )\n",
    "        super().__init__(id=id)\n",
    "\n",
    "    @handler\n",
    "    async def handle(self, messages: list[ChatMessage], ctx: WorkflowContext[Never, str]) -> None:\n",
    "        \"\"\"Review the full conversation transcript and yield the final output.\n",
    "\n",
    "        This node consumes all messages so far. It uses its agent to produce the final text,\n",
    "        then yields the output. The workflow completes when it becomes idle.\n",
    "        \"\"\"\n",
    "        response = await self.agent.run(messages)\n",
    "        await ctx.yield_output(response.text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f53cc8",
   "metadata": {},
   "source": [
    "### Workflow Flow Diagram\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[User Input<br/>ChatMessage] --> B[Writer Executor<br/>Content Generation Agent]\n",
    "    B --> C[Reviewer Executor<br/>Content Review Agent]\n",
    "    C --> D[Final Output<br/>Reviewed Text]\n",
    "\n",
    "    subgraph \"Workflow Details\"\n",
    "        E[Writer receives ChatMessage<br/>Creates content<br/>Forwards conversation to Reviewer]\n",
    "        F[Reviewer receives full conversation<br/>Reviews and refines content<br/>Yields final output]\n",
    "    end\n",
    "\n",
    "    B -.-> E\n",
    "    C -.-> F\n",
    "\n",
    "    style A fill:#e1f5fe\n",
    "    style B fill:#f3e5f5\n",
    "    style C fill:#e8f5e8\n",
    "    style D fill:#fff3e0\n",
    "```\n",
    "\n",
    "This diagram shows the flow created by:\n",
    "```python\n",
    "workflow = WorkflowBuilder().set_start_executor(writer).add_edge(writer, reviewer).build()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Stream the workflow events\n",
    "The `main()` coroutine builds the workflow, calls `run_stream()`, and prints status updates, outputs, and errors as they surface.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    \"\"\"Build the two node workflow and run it with streaming to observe events.\"\"\"\n",
    "    # Create the Azure chat client. AzureCliCredential uses your current az login.\n",
    "    chat_client = AzureOpenAIChatClient(credential=AzureCliCredential())\n",
    "    # Instantiate the two agent backed executors.\n",
    "    writer = Writer(chat_client)\n",
    "    reviewer = Reviewer(chat_client)\n",
    "\n",
    "    # Build the workflow using the fluent builder.\n",
    "    # Set the start node and connect an edge from writer to reviewer.\n",
    "    workflow = WorkflowBuilder().set_start_executor(writer).add_edge(writer, reviewer).build()\n",
    "\n",
    "    # Run the workflow with the user's initial message and stream events as they occur.\n",
    "    # This surfaces executor events, workflow outputs, run-state changes, and errors.\n",
    "    async for event in workflow.run_stream(\n",
    "        ChatMessage(role=\"user\", text=\"Create a slogan for a new electric SUV that is affordable and fun to drive.\")\n",
    "    ):\n",
    "        if isinstance(event, WorkflowStatusEvent):\n",
    "            prefix = f\"State ({event.origin.value}): \"\n",
    "            if event.state == WorkflowRunState.IN_PROGRESS:\n",
    "                print(prefix + \"IN_PROGRESS\")\n",
    "            elif event.state == WorkflowRunState.IN_PROGRESS_PENDING_REQUESTS:\n",
    "                print(prefix + \"IN_PROGRESS_PENDING_REQUESTS (requests in flight)\")\n",
    "            elif event.state == WorkflowRunState.IDLE:\n",
    "                print(prefix + \"IDLE (no active work)\")\n",
    "            elif event.state == WorkflowRunState.IDLE_WITH_PENDING_REQUESTS:\n",
    "                print(prefix + \"IDLE_WITH_PENDING_REQUESTS (prompt user or UI now)\")\n",
    "            else:\n",
    "                print(prefix + str(event.state))\n",
    "        elif isinstance(event, WorkflowOutputEvent):\n",
    "            print(f\"Workflow output ({event.origin.value}): {event.data}\")\n",
    "        elif isinstance(event, ExecutorFailedEvent):\n",
    "            print(\n",
    "                f\"Executor failed ({event.origin.value}): \"\n",
    "                f\"{event.executor_id} {event.details.error_type}: {event.details.message}\"\n",
    "            )\n",
    "        elif isinstance(event, WorkflowFailedEvent):\n",
    "            details = event.details\n",
    "            print(f\"Workflow failed ({event.origin.value}): {details.error_type}: {details.message}\")\n",
    "        else:\n",
    "            print(f\"{event.__class__.__name__} ({event.origin.value}): {event}\")\n",
    "\n",
    "    \"\"\"\n",
    "    Sample Output:\n",
    "\n",
    "    State (RUNNER): IN_PROGRESS\n",
    "    ExecutorInvokeEvent (RUNNER): ExecutorInvokeEvent(executor_id=writer)\n",
    "    ExecutorCompletedEvent (RUNNER): ExecutorCompletedEvent(executor_id=writer)\n",
    "    ExecutorInvokeEvent (RUNNER): ExecutorInvokeEvent(executor_id=reviewer)\n",
    "    Workflow output (EXECUTOR): Drive the Future. Affordable Adventure, Electrified.\n",
    "    ExecutorCompletedEvent (RUNNER): ExecutorCompletedEvent(executor_id=reviewer)\n",
    "    State (RUNNER): IDLE\n",
    "    \"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Try it yourself\n",
    "Use the helper below. In notebooks it awaits `main()` on the active loop; in scripts it falls back to `asyncio.run(main())`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WorkflowStartedEvent (FRAMEWORK): WorkflowStartedEvent(origin=WorkflowEventSource.FRAMEWORK, data=None)\n",
      "State (FRAMEWORK): IN_PROGRESS\n",
      "ExecutorInvokedEvent (FRAMEWORK): ExecutorInvokedEvent(executor_id=writer, data=None)\n",
      "ExecutorCompletedEvent (FRAMEWORK): ExecutorCompletedEvent(executor_id=writer, data=None)\n",
      "ExecutorInvokedEvent (FRAMEWORK): ExecutorInvokedEvent(executor_id=reviewer, data=None)\n",
      "Workflow output (FRAMEWORK): Here’s a quick review of the set you provided, plus some suggestions to sharpen them.\n",
      "\n",
      "What works well\n",
      "- Energy and benefit pairing: Most slogans connect driving joy with affordability, which matches the brief.\n",
      "- Clear value proposition: “affordable,” “electric,” and “fun to drive” are explicit.\n",
      "- Catchy rhythm: Several lines have a snappy cadence that’s easy to remember.\n",
      "\n",
      "Areas to tighten\n",
      "- Grammar and flow: A couple phrases feel slightly awkward or clunky (e.g., “Charge less, drive more thrill,” “Electric joy, everyday price” is good, but could be smoother).\n",
      "- Consistency: Some use “electric” early, others don’t; pick a consistent hook (affordability, fun, or sustainability).\n",
      "- Differentiation: The slogans are strong on value and fun but don’t hint at any unique tech or design angle (range, charging speed, interior tech). A touch more specificity can help stand out.\n",
      "- Tone balance: A few lines lean generic. If your brand has a playful, adventurous vibe, push that and maybe add a bit of personality or imagery.\n",
      "\n",
      "Suggestions to improve\n",
      "- Fix tiny grammar glitches and strengthen cadence.\n",
      "- Consider a stronger verb or image to evoke “driving fun” and “affordability” in one breath.\n",
      "- If you have a standout tech angle (e.g., range, charging, lightweight design), weave it in subtly.\n",
      "- Keep length short for versatile use (ads, social, decals, etc.).\n",
      "\n",
      "Revised options (sharper, with consistent rhythm and a touch more personality)\n",
      "- Fun to drive. Easy on the wallet. Electric all the way.\n",
      "- Spark your ride. Price that puts a smile in every mile.\n",
      "- Electric joy, everyday price.\n",
      "- Go electric. Go fun. Go affordable.\n",
      "- Charge less. Drive more thrill.\n",
      "- Thrill you can afford. Power you can feel.\n",
      "- Fun is electric. The price is friendly.\n",
      "- Affordability meets exhilaration, in every mile.\n",
      "\n",
      "If you want, tell me the brand voice (playful, rugged, premium, tech-forward, etc.) and any unique features (range, charging speed, size, sustainability angle). I can tailor a fresh set that aligns with your identity and testable hooks.\n",
      "ExecutorCompletedEvent (FRAMEWORK): ExecutorCompletedEvent(executor_id=reviewer, data=None)\n",
      "State (FRAMEWORK): IDLE (no active work)\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "# Helper for notebooks vs. scripts\n",
    "loop = asyncio.get_event_loop()\n",
    "if loop.is_running():\n",
    "    # Jupyter/VS Code notebooks already have an event loop, so await directly.\n",
    "    await main()\n",
    "else:\n",
    "    asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99afe7d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
