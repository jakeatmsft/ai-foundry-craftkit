{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sub_workflow_parallel_requests.py - ELI5 Walkthrough\n",
    "This notebook rebuilds `python/samples/getting_started/workflows/composition/sub_workflow_parallel_requests.py` with commentary between each section.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big Picture\n",
    "A sub-workflow emits both resource allocation requests and policy checks. The parent workflow routes each message type to a specialized interceptor (cache vs. policy engine) and only hands misses off to an external service.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Ingredients\n",
    "- Typed `RequestInfoMessage` subclasses (`ResourceRequest`, `PolicyCheckRequest`) enable type-safe routing.\n",
    "- Interceptors use `@handler` methods with those types to react only to relevant messages.\n",
    "- `WorkflowExecutor` embeds the resource requester workflow inside the parent graph.\n",
    "- External requests are simulated via `RequestInfoExecutor` for cache misses or policy escalations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow Diagram\n",
    "```mermaid\n",
    "flowchart LR\n",
    "    Start([\"Mixed Requests\"]) --> Coordinator[[Coordinator]]\n",
    "    Coordinator --> SubWF[[WorkflowExecutor]]\n",
    "    SubWF --> Cache[[ResourceCache]]\n",
    "    SubWF --> Policy[[PolicyEngine]]\n",
    "    Cache --> SubWF\n",
    "    Policy --> SubWF\n",
    "    Cache --> External[/RequestInfoExecutor/]\n",
    "    Policy --> External\n",
    "    External --> SubWF\n",
    "    SubWF --> Coordinator\n",
    "    Coordinator --> Output([\"All Requests Completed\"])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Imports and scenario overview\n",
    "We load Agent Framework primitives, configure the environment, and include the detailed docstring describing the routing pattern.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Microsoft. All rights reserved.\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import asyncio\n",
    "from dataclasses import dataclass\n",
    "from typing import Any\n",
    "\n",
    "from agent_framework import (\n",
    "    Executor,\n",
    "    RequestInfoExecutor,\n",
    "    RequestInfoMessage,\n",
    "    RequestResponse,\n",
    "    WorkflowBuilder,\n",
    "    WorkflowContext,\n",
    "    WorkflowExecutor,\n",
    "    handler,\n",
    ")\n",
    "from typing_extensions import Never\n",
    "\n",
    "\"\"\"\n",
    "Sample: Sub-workflow with parallel request handling by specialized interceptors\n",
    "\n",
    "This sample demonstrates how different parent executors can handle different types of requests\n",
    "from the same sub-workflow using regular @handler methods for RequestInfoMessage subclasses.\n",
    "\n",
    "Prerequisites:\n",
    "- No external services required (external handling simulated via `RequestInfoExecutor`).\n",
    "\n",
    "Key architectural principles:\n",
    "1. Specialized interceptors: Each parent executor handles only specific request types\n",
    "2. Type-based routing: ResourceCache handles ResourceRequest, PolicyEngine handles PolicyCheckRequest\n",
    "3. Automatic type filtering: Each interceptor only receives requests with matching types\n",
    "4. Fallback forwarding: Unhandled requests are forwarded to external services\n",
    "\n",
    "The example simulates a resource allocation system where:\n",
    "- Sub-workflow makes mixed requests for resources (CPU, memory) and policy checks\n",
    "- ResourceCache executor intercepts ResourceRequest messages, serves from cache or forwards\n",
    "- PolicyEngine executor intercepts PolicyCheckRequest messages, applies rules or forwards\n",
    "- Each interceptor uses typed @handler methods for automatic filtering\n",
    "\n",
    "Flow visualization:\n",
    "\n",
    "  Coordinator\n",
    "      |\n",
    "      |  Mixed list[resource + policy requests]\n",
    "      v\n",
    "    [ Sub-workflow: WorkflowExecutor(ResourceRequester) ]\n",
    "      |\n",
    "      |  Emits different RequestInfoMessage types:\n",
    "      |     - ResourceRequest\n",
    "      |     - PolicyCheckRequest\n",
    "      v\n",
    "  Parent workflow routes to specialized handlers:\n",
    "      |                                    |\n",
    "      | ResourceCache.handle_resource_request | PolicyEngine.handle_policy_request\n",
    "      | (@handler ResourceRequest)          | (@handler PolicyCheckRequest)\n",
    "      v                                    v\n",
    "  Cache hit/miss decision              Policy allow/deny decision\n",
    "      |                                    |\n",
    "      | RequestResponse OR forward        | RequestResponse OR forward\n",
    "      v                                    v\n",
    "  Back to sub-workflow  <----------> External RequestInfoExecutor\n",
    "                                           |\n",
    "                                           v\n",
    "                                    External responses route back\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Domain-specific request and response models\n",
    "These dataclasses shape the messages flowing between the sub-workflow, interceptors, and external services.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define domain-specific request/response types\n",
    "@dataclass\n",
    "class ResourceRequest(RequestInfoMessage):\n",
    "    \"\"\"Request for computing resources.\"\"\"\n",
    "\n",
    "    resource_type: str = \"cpu\"  # cpu, memory, disk, etc.\n",
    "    amount: int = 1\n",
    "    priority: str = \"normal\"  # low, normal, high\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PolicyCheckRequest(RequestInfoMessage):\n",
    "    \"\"\"Request to check resource allocation policy.\"\"\"\n",
    "\n",
    "    resource_type: str = \"\"\n",
    "    amount: int = 0\n",
    "    policy_type: str = \"quota\"  # quota, compliance, security\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ResourceResponse:\n",
    "    \"\"\"Response with allocated resources.\"\"\"\n",
    "\n",
    "    resource_type: str\n",
    "    allocated: int\n",
    "    source: str  # Which system provided the resources\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PolicyResponse:\n",
    "    \"\"\"Response from policy check.\"\"\"\n",
    "\n",
    "    approved: bool\n",
    "    reason: str\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class RequestFinished:\n",
    "    pass\n",
    "\n",
    "\n",
    "# 2. Implement the sub-workflow executor - makes resource and policy requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: The sub-workflow requester\n",
    "`ResourceRequester` loops over incoming work, emits either `ResourceRequest` or `PolicyCheckRequest`, and waits for typed `RequestResponse` messages to complete.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResourceRequester(Executor):\n",
    "    \"\"\"Simple executor that requests resources and checks policies.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(id=\"resource_requester\")\n",
    "        self._request_count = 0\n",
    "\n",
    "    @handler\n",
    "    async def request_resources(\n",
    "        self,\n",
    "        requests: list[dict[str, Any]],\n",
    "        ctx: WorkflowContext[ResourceRequest | PolicyCheckRequest],\n",
    "    ) -> None:\n",
    "        \"\"\"Process a list of resource requests.\"\"\"\n",
    "        print(f\"\ud83c\udfed Sub-workflow processing {len(requests)} requests\")\n",
    "        self._request_count += len(requests)\n",
    "\n",
    "        for req_data in requests:\n",
    "            req_type = req_data.get(\"request_type\", \"resource\")\n",
    "\n",
    "            request: ResourceRequest | PolicyCheckRequest\n",
    "            if req_type == \"resource\":\n",
    "                print(f\"  \ud83d\udce6 Requesting resource: {req_data.get('type', 'cpu')} x{req_data.get('amount', 1)}\")\n",
    "                request = ResourceRequest(\n",
    "                    resource_type=req_data.get(\"type\", \"cpu\"),\n",
    "                    amount=req_data.get(\"amount\", 1),\n",
    "                    priority=req_data.get(\"priority\", \"normal\"),\n",
    "                )\n",
    "                # Send to parent workflow for interception - not to target_id\n",
    "                await ctx.send_message(request)\n",
    "            elif req_type == \"policy\":\n",
    "                print(\n",
    "                    f\"  \ud83d\udee1\ufe0f  Checking policy: {req_data.get('type', 'cpu')} x{req_data.get('amount', 1)} \"\n",
    "                    f\"({req_data.get('policy_type', 'quota')})\"\n",
    "                )\n",
    "                request = PolicyCheckRequest(\n",
    "                    resource_type=req_data.get(\"type\", \"cpu\"),\n",
    "                    amount=req_data.get(\"amount\", 1),\n",
    "                    policy_type=req_data.get(\"policy_type\", \"quota\"),\n",
    "                )\n",
    "                # Send to parent workflow for interception - not to target_id\n",
    "                await ctx.send_message(request)\n",
    "\n",
    "    @handler\n",
    "    async def handle_resource_response(\n",
    "        self,\n",
    "        response: RequestResponse[ResourceRequest, ResourceResponse],\n",
    "        ctx: WorkflowContext[Never, RequestFinished],\n",
    "    ) -> None:\n",
    "        \"\"\"Handle resource allocation response.\"\"\"\n",
    "        if response.data:\n",
    "            source_icon = \"\ud83c\udfea\" if response.data.source == \"cache\" else \"\ud83c\udf10\"\n",
    "            print(\n",
    "                f\"\ud83d\udce6 {source_icon} Sub-workflow received: {response.data.allocated} {response.data.resource_type} \"\n",
    "                f\"from {response.data.source}\"\n",
    "            )\n",
    "            if self._collect_results():\n",
    "                # Yield completion result to the parent workflow.\n",
    "                await ctx.yield_output(RequestFinished())\n",
    "\n",
    "    @handler\n",
    "    async def handle_policy_response(\n",
    "        self,\n",
    "        response: RequestResponse[PolicyCheckRequest, PolicyResponse],\n",
    "        ctx: WorkflowContext[Never, RequestFinished],\n",
    "    ) -> None:\n",
    "        \"\"\"Handle policy check response.\"\"\"\n",
    "        if response.data:\n",
    "            status_icon = \"\u2705\" if response.data.approved else \"\u274c\"\n",
    "            print(\n",
    "                f\"\ud83d\udee1\ufe0f  {status_icon} Sub-workflow received policy response: \"\n",
    "                f\"{response.data.approved} - {response.data.reason}\"\n",
    "            )\n",
    "            if self._collect_results():\n",
    "                # Yield completion result to the parent workflow.\n",
    "                await ctx.yield_output(RequestFinished())\n",
    "\n",
    "    def _collect_results(self) -> bool:\n",
    "        \"\"\"Collect and summarize results.\"\"\"\n",
    "        self._request_count -= 1\n",
    "        print(f\"\ud83d\udcca Sub-workflow completed request ({self._request_count} remaining)\")\n",
    "        return self._request_count == 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Resource cache interceptor\n",
    "`ResourceCache` inspects each `ResourceRequest`, serves cache hits immediately, and forwards misses to the external `RequestInfoExecutor`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Implement the Resource Cache - Uses typed handler for ResourceRequest\n",
    "class ResourceCache(Executor):\n",
    "    \"\"\"Interceptor that handles RESOURCE requests from cache using typed routing.\"\"\"\n",
    "\n",
    "    # Use class attributes to avoid Pydantic assignment restrictions\n",
    "    cache: dict[str, int] = {\"cpu\": 10, \"memory\": 50, \"disk\": 100}\n",
    "    results: list[ResourceResponse] = []\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(id=\"resource_cache\")\n",
    "        # Instance initialization only; state kept in class attributes as above\n",
    "\n",
    "    @handler\n",
    "    async def handle_resource_request(\n",
    "        self, request: ResourceRequest, ctx: WorkflowContext[RequestResponse[ResourceRequest, Any] | ResourceRequest]\n",
    "    ) -> None:\n",
    "        \"\"\"Handle RESOURCE requests from sub-workflows and check cache first.\"\"\"\n",
    "        resource_request = request\n",
    "        print(f\"\ud83c\udfea CACHE interceptor checking: {resource_request.amount} {resource_request.resource_type}\")\n",
    "\n",
    "        available = self.cache.get(resource_request.resource_type, 0)\n",
    "\n",
    "        if available >= resource_request.amount:\n",
    "            # We can satisfy from cache\n",
    "            self.cache[resource_request.resource_type] -= resource_request.amount\n",
    "            response_data = ResourceResponse(\n",
    "                resource_type=resource_request.resource_type, allocated=resource_request.amount, source=\"cache\"\n",
    "            )\n",
    "            print(f\"  \u2705 Cache satisfied: {resource_request.amount} {resource_request.resource_type}\")\n",
    "            self.results.append(response_data)\n",
    "\n",
    "            # Send response back to sub-workflow\n",
    "            response = RequestResponse(data=response_data, original_request=request, request_id=request.request_id)\n",
    "            await ctx.send_message(response, target_id=request.source_executor_id)\n",
    "        else:\n",
    "            # Cache miss - forward to external\n",
    "            print(f\"  \u274c Cache miss: need {resource_request.amount}, have {available} {resource_request.resource_type}\")\n",
    "            await ctx.send_message(request)\n",
    "\n",
    "    @handler\n",
    "    async def collect_result(\n",
    "        self, response: RequestResponse[ResourceRequest, ResourceResponse], ctx: WorkflowContext\n",
    "    ) -> None:\n",
    "        \"\"\"Collect results from external requests that were forwarded.\"\"\"\n",
    "        if response.data and response.data.source != \"cache\":  # Don't double-count our own results\n",
    "            self.results.append(response.data)\n",
    "            print(\n",
    "                f\"\ud83c\udfea \ud83c\udf10 Cache received external response: {response.data.allocated} {response.data.resource_type} \"\n",
    "                f\"from {response.data.source}\"\n",
    "            )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Policy engine interceptor\n",
    "`PolicyEngine` applies quota rules to `PolicyCheckRequest` messages and only escalates cases it cannot approve locally.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Implement the Policy Engine - Uses typed handler for PolicyCheckRequest\n",
    "class PolicyEngine(Executor):\n",
    "    \"\"\"Interceptor that handles POLICY requests using typed routing.\"\"\"\n",
    "\n",
    "    # Use class attributes for simple sample state\n",
    "    quota: dict[str, int] = {\n",
    "        \"cpu\": 5,  # Only allow up to 5 CPU units\n",
    "        \"memory\": 20,  # Only allow up to 20 memory units\n",
    "        \"disk\": 1000,  # Liberal disk policy\n",
    "    }\n",
    "    results: list[PolicyResponse] = []\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(id=\"policy_engine\")\n",
    "        # Instance initialization only; state kept in class attributes as above\n",
    "\n",
    "    @handler\n",
    "    async def handle_policy_request(\n",
    "        self, request: PolicyCheckRequest, ctx: WorkflowContext[RequestResponse[PolicyCheckRequest, Any] | PolicyCheckRequest]\n",
    "    ) -> None:\n",
    "        \"\"\"Handle POLICY requests from sub-workflows and apply rules.\"\"\"\n",
    "        policy_request = request\n",
    "        print(f\"\ud83d\udee1\ufe0f  POLICY interceptor checking: {policy_request.amount} {policy_request.resource_type}, policy={policy_request.policy_type}\")\n",
    "\n",
    "        quota_limit = self.quota.get(policy_request.resource_type, 0)\n",
    "\n",
    "        if policy_request.policy_type == \"quota\":\n",
    "            if policy_request.amount <= quota_limit:\n",
    "                response_data = PolicyResponse(approved=True, reason=f\"Within quota ({quota_limit})\")\n",
    "                print(f\"  \u2705 Policy approved: {policy_request.amount} <= {quota_limit}\")\n",
    "                self.results.append(response_data)\n",
    "\n",
    "                # Send response back to sub-workflow\n",
    "                response = RequestResponse(data=response_data, original_request=request, request_id=request.request_id)\n",
    "                await ctx.send_message(response, target_id=request.source_executor_id)\n",
    "                return\n",
    "\n",
    "            # Exceeds quota - forward to external for review\n",
    "            print(f\"  \u274c Policy exceeds quota: {policy_request.amount} > {quota_limit}, forwarding to external\")\n",
    "            await ctx.send_message(request)\n",
    "            return\n",
    "\n",
    "        # Unknown policy type - forward to external\n",
    "        print(f\"  \u2753 Unknown policy type: {policy_request.policy_type}, forwarding\")\n",
    "        await ctx.send_message(request)\n",
    "\n",
    "    @handler\n",
    "    async def collect_policy_result(\n",
    "        self, response: RequestResponse[PolicyCheckRequest, PolicyResponse], ctx: WorkflowContext\n",
    "    ) -> None:\n",
    "        \"\"\"Collect policy results from external requests that were forwarded.\"\"\"\n",
    "        if response.data:\n",
    "            self.results.append(response.data)\n",
    "            print(f\"\ud83d\udee1\ufe0f  \ud83c\udf10 Policy received external response: {response.data.approved} - {response.data.reason}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Coordinator and orchestration\n",
    "The coordinator kicks off the sub-workflow, listens for completion, and the parent `main()` function wires together interceptors, sub-workflow, and the external request handler.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Coordinator(Executor):\n",
    "    def __init__(self):\n",
    "        super().__init__(id=\"coordinator\")\n",
    "\n",
    "    @handler\n",
    "    async def start(self, requests: list[dict[str, Any]], ctx: WorkflowContext[list[dict[str, Any]]]) -> None:\n",
    "        \"\"\"Start the resource allocation process.\"\"\"\n",
    "        await ctx.send_message(requests, target_id=\"resource_workflow\")\n",
    "\n",
    "    @handler\n",
    "    async def handle_completion(self, completion: RequestFinished, ctx: WorkflowContext) -> None:\n",
    "        \"\"\"Handle sub-workflow completion.\n",
    "\n",
    "        It comes from the sub-workflow yielded output.\n",
    "        \"\"\"\n",
    "        print(\"\ud83c\udfaf Main workflow received completion.\")\n",
    "\n",
    "\n",
    "async def main() -> None:\n",
    "    \"\"\"Demonstrate parallel request interception patterns.\"\"\"\n",
    "    print(\"\ud83d\ude80 Starting Sub-Workflow Parallel Request Interception Demo...\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # 5. Create the sub-workflow\n",
    "    resource_requester = ResourceRequester()\n",
    "    sub_request_info = RequestInfoExecutor(id=\"sub_request_info\")\n",
    "\n",
    "    sub_workflow = (\n",
    "        WorkflowBuilder()\n",
    "        .set_start_executor(resource_requester)\n",
    "        .add_edge(resource_requester, sub_request_info)\n",
    "        .add_edge(sub_request_info, resource_requester)\n",
    "        .build()\n",
    "    )\n",
    "\n",
    "    # 6. Create parent workflow with PROPER interceptor pattern\n",
    "    cache = ResourceCache()  # Intercepts ResourceRequest\n",
    "    policy = PolicyEngine()  # Intercepts PolicyCheckRequest (different type!)\n",
    "    workflow_executor = WorkflowExecutor(sub_workflow, id=\"resource_workflow\")\n",
    "    main_request_info = RequestInfoExecutor(id=\"main_request_info\")\n",
    "\n",
    "    # Create a simple coordinator that starts the process\n",
    "    coordinator = Coordinator()\n",
    "\n",
    "    # TYPED ROUTING: Each executor handles specific typed RequestInfoMessage messages\n",
    "    main_workflow = (\n",
    "        WorkflowBuilder()\n",
    "        .set_start_executor(coordinator)\n",
    "        .add_edge(coordinator, workflow_executor)  # Start sub-workflow\n",
    "        .add_edge(workflow_executor, coordinator)  # Sub-workflow completion back to coordinator\n",
    "        .add_edge(workflow_executor, cache)  # WorkflowExecutor sends ResourceRequest to cache\n",
    "        .add_edge(workflow_executor, policy)  # WorkflowExecutor sends PolicyCheckRequest to policy\n",
    "        .add_edge(cache, workflow_executor)  # Cache sends RequestResponse back\n",
    "        .add_edge(policy, workflow_executor)  # Policy sends RequestResponse back\n",
    "        .add_edge(cache, main_request_info)  # Cache forwards ResourceRequest to external\n",
    "        .add_edge(policy, main_request_info)  # Policy forwards PolicyCheckRequest to external\n",
    "        .add_edge(main_request_info, workflow_executor)  # External responses back to sub-workflow\n",
    "        .build()\n",
    "    )\n",
    "\n",
    "    # 7. Test with various requests (mixed resource and policy)\n",
    "    test_requests = [\n",
    "        {\"request_type\": \"resource\", \"type\": \"cpu\", \"amount\": 2, \"priority\": \"normal\"},  # Cache hit\n",
    "        {\"request_type\": \"policy\", \"type\": \"cpu\", \"amount\": 3, \"policy_type\": \"quota\"},  # Policy hit\n",
    "        {\"request_type\": \"resource\", \"type\": \"memory\", \"amount\": 15, \"priority\": \"normal\"},  # Cache hit\n",
    "        {\"request_type\": \"policy\", \"type\": \"memory\", \"amount\": 100, \"policy_type\": \"quota\"},  # Policy miss -> external\n",
    "        {\"request_type\": \"resource\", \"type\": \"gpu\", \"amount\": 1, \"priority\": \"high\"},  # Cache miss -> external\n",
    "        {\"request_type\": \"policy\", \"type\": \"disk\", \"amount\": 500, \"policy_type\": \"quota\"},  # Policy hit\n",
    "        {\"request_type\": \"policy\", \"type\": \"cpu\", \"amount\": 1, \"policy_type\": \"security\"},  # Unknown policy -> external\n",
    "    ]\n",
    "\n",
    "    print(f\"\ud83e\uddea Testing with {len(test_requests)} mixed requests:\")\n",
    "    for i, req in enumerate(test_requests, 1):\n",
    "        req_icon = \"\ud83d\udce6\" if req[\"request_type\"] == \"resource\" else \"\ud83d\udee1\ufe0f\"\n",
    "        print(\n",
    "            f\"  {i}. {req_icon} {req['type']} x{req['amount']} \"\n",
    "            f\"({req.get('priority', req.get('policy_type', 'default'))})\"\n",
    "        )\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    # 8. Run the workflow\n",
    "    print(\"\ud83c\udfac Running workflow...\")\n",
    "    events = await main_workflow.run(test_requests)\n",
    "\n",
    "    # 9. Handle any external requests that couldn't be intercepted\n",
    "    request_events = events.get_request_info_events()\n",
    "    if request_events:\n",
    "        print(f\"\\n\ud83c\udf10 Handling {len(request_events)} external request(s)...\")\n",
    "\n",
    "        external_responses: dict[str, Any] = {}\n",
    "        for event in request_events:\n",
    "            if isinstance(event.data, ResourceRequest):\n",
    "                # Handle ResourceRequest - create ResourceResponse\n",
    "                resource_response = ResourceResponse(\n",
    "                    resource_type=event.data.resource_type, allocated=event.data.amount, source=\"external_provider\"\n",
    "                )\n",
    "                external_responses[event.request_id] = resource_response\n",
    "                print(f\"  \ud83c\udfed External provider: {resource_response.allocated} {resource_response.resource_type}\")\n",
    "            elif isinstance(event.data, PolicyCheckRequest):\n",
    "                # Handle PolicyCheckRequest - create PolicyResponse\n",
    "                policy_response = PolicyResponse(approved=True, reason=\"External policy service approved\")\n",
    "                external_responses[event.request_id] = policy_response\n",
    "                print(f\"  \ud83d\udd12 External policy: {'\u2705 APPROVED' if policy_response.approved else '\u274c DENIED'}\")\n",
    "\n",
    "        await main_workflow.send_responses(external_responses)\n",
    "    else:\n",
    "        print(\"\\n\ud83c\udfaf All requests were intercepted internally!\")\n",
    "\n",
    "    # 10. Show results and analysis\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"\ud83d\udcca RESULTS ANALYSIS\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    print(f\"\\n\ud83c\udfea Cache Results ({len(cache.results)} handled):\")\n",
    "    for result in cache.results:\n",
    "        print(f\"  \u2705 {result.allocated} {result.resource_type} from {result.source}\")\n",
    "\n",
    "    print(f\"\\n\ud83d\udee1\ufe0f  Policy Results ({len(policy.results)} handled):\")\n",
    "    for result in policy.results:\n",
    "        status_icon = \"\u2705\" if result.approved else \"\u274c\"\n",
    "        print(f\"  {status_icon} Approved: {result.approved} - {result.reason}\")\n",
    "\n",
    "    print(\"\\n\ud83d\udcbe Final Cache State:\")\n",
    "    for resource, amount in cache.cache.items():\n",
    "        print(f\"  \ud83d\udce6 {resource}: {amount} remaining\")\n",
    "\n",
    "    print(\"\\n\ud83d\udcc8 Summary:\")\n",
    "    print(f\"  \ud83c\udfaf Total requests: {len(test_requests)}\")\n",
    "    print(f\"  \ud83c\udfea Resource requests handled: {len(cache.results)}\")\n",
    "    print(f\"  \ud83d\udee1\ufe0f  Policy requests handled: {len(policy.results)}\")\n",
    "    print(f\"  \ud83c\udf10 External requests: {len(request_events) if request_events else 0}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Try it yourself\n",
    "Use the helper below. In notebooks it awaits `main()` on the active loop; in scripts it falls back to `asyncio.run(main())`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "# Helper for notebooks vs. scripts\n",
    "loop = asyncio.get_event_loop()\n",
    "if loop.is_running():\n",
    "    # Jupyter/VS Code notebooks already have an event loop, so await directly.\n",
    "    await main()\n",
    "else:\n",
    "    asyncio.run(main())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
