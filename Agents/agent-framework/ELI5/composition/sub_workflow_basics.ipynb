{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sub_workflow_basics.py - ELI5 Walkthrough\n",
    "This notebook recreates `python/samples/getting_started/workflows/composition/sub_workflow_basics.py` so you can see each piece in context.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big Picture\n",
    "A parent workflow fan-outs text snippets to a sub-workflow that counts words and characters. Once every sub-workflow finishes, the parent collates the results and prints a summary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Ingredients\n",
    "- `WorkflowExecutor` lets the parent treat another workflow like an executor node.\n",
    "- `TextProcessor` runs in the sub-workflow and yields `TextProcessingResult` objects.\n",
    "- The orchestrator collects results, fires a custom `AllTasksCompleted` event, and prints a report.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow Diagram\n",
    "```mermaid\n",
    "flowchart LR\n",
    "    Start([\"Text List\"]) --> Orchestrator[[TextProcessingOrchestrator]]\n",
    "    Orchestrator --> SubWF[[WorkflowExecutor]]\n",
    "    subgraph SubWorkflow\n",
    "        Processor[[TextProcessor]]\n",
    "    end\n",
    "    SubWF --> Orchestrator\n",
    "    Orchestrator --> Output([\"Aggregated Results\"])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load dependencies and explain the scenario\n",
    "We import Agent Framework helpers, set up environment variables, and include the narrated docstring describing the demo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Microsoft. All rights reserved.\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import asyncio\n",
    "from dataclasses import dataclass\n",
    "from typing import Any\n",
    "\n",
    "from agent_framework import (\n",
    "    Executor,\n",
    "    WorkflowBuilder,\n",
    "    WorkflowContext,\n",
    "    WorkflowEvent,\n",
    "    WorkflowExecutor,\n",
    "    handler,\n",
    ")\n",
    "from typing_extensions import Never\n",
    "\n",
    "\"\"\"\n",
    "Sample: Sub-Workflows (Basics)\n",
    "\n",
    "What it does:\n",
    "- Shows how a parent workflow invokes a sub-workflow via `WorkflowExecutor` and collects results.\n",
    "- Example: parent orchestrates multiple text processors that count words/characters.\n",
    "- Demonstrates how sub-workflows complete by yielding outputs when processing is done.\n",
    "\n",
    "Prerequisites:\n",
    "- No external services required.\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Define message types and events\n",
    "Requests and results travel between the parent workflow and the sub-workflow. A custom `WorkflowEvent` signals when everything finishes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Message types\n",
    "@dataclass\n",
    "class TextProcessingRequest:\n",
    "    \"\"\"Request to process a text string.\"\"\"\n",
    "\n",
    "    text: str\n",
    "    task_id: str\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TextProcessingResult:\n",
    "    \"\"\"Result of text processing.\"\"\"\n",
    "\n",
    "    task_id: str\n",
    "    text: str\n",
    "    word_count: int\n",
    "    char_count: int\n",
    "\n",
    "\n",
    "class AllTasksCompleted(WorkflowEvent):\n",
    "    \"\"\"Event triggered when all processing tasks are complete.\"\"\"\n",
    "\n",
    "    def __init__(self, results: list[TextProcessingResult]):\n",
    "        super().__init__(results)\n",
    "\n",
    "\n",
    "# Sub-workflow executor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Build the sub-workflow executor\n",
    "`TextProcessor` performs the work for a single text: it logs progress, counts words/characters, and yields a result back to whoever invoked it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextProcessor(Executor):\n",
    "    \"\"\"Processes text strings - counts words and characters.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(id=\"text_processor\")\n",
    "\n",
    "    @handler\n",
    "    async def process_text(\n",
    "        self, request: TextProcessingRequest, ctx: WorkflowContext[Never, TextProcessingResult]\n",
    "    ) -> None:\n",
    "        \"\"\"Process a text string and return statistics.\"\"\"\n",
    "        text_preview = f\"'{request.text[:50]}{'...' if len(request.text) > 50 else ''}'\"\n",
    "        print(f\"\ud83d\udd0d Sub-workflow processing text (Task {request.task_id}): {text_preview}\")\n",
    "\n",
    "        # Simple text processing\n",
    "        word_count = len(request.text.split()) if request.text.strip() else 0\n",
    "        char_count = len(request.text)\n",
    "\n",
    "        print(f\"\ud83d\udcca Task {request.task_id}: {word_count} words, {char_count} characters\")\n",
    "\n",
    "        # Create result\n",
    "        result = TextProcessingResult(\n",
    "            task_id=request.task_id,\n",
    "            text=request.text,\n",
    "            word_count=word_count,\n",
    "            char_count=char_count,\n",
    "        )\n",
    "\n",
    "        print(f\"\u2705 Sub-workflow completed task {request.task_id}\")\n",
    "        # Signal completion by yielding the result\n",
    "        await ctx.yield_output(result)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Orchestrate all tasks\n",
    "`TextProcessingOrchestrator` dispatches each text to the sub-workflow, collects results, and aggregates statistics for reporting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parent workflow\n",
    "class TextProcessingOrchestrator(Executor):\n",
    "    \"\"\"Orchestrates multiple text processing tasks using sub-workflows.\"\"\"\n",
    "\n",
    "    results: list[TextProcessingResult] = []\n",
    "    expected_count: int = 0\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(id=\"text_orchestrator\")\n",
    "\n",
    "    @handler\n",
    "    async def start_processing(self, texts: list[str], ctx: WorkflowContext[TextProcessingRequest]) -> None:\n",
    "        \"\"\"Start processing multiple text strings.\"\"\"\n",
    "        print(f\"\ud83d\udcc4 Starting processing of {len(texts)} text strings\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        self.expected_count = len(texts)\n",
    "\n",
    "        # Send each text to a sub-workflow\n",
    "        for i, text in enumerate(texts):\n",
    "            task_id = f\"task_{i + 1}\"\n",
    "            request = TextProcessingRequest(text=text, task_id=task_id)\n",
    "            print(f\"\ud83d\udce4 Dispatching {task_id} to sub-workflow\")\n",
    "            await ctx.send_message(request, target_id=\"text_processor_workflow\")\n",
    "\n",
    "    @handler\n",
    "    async def collect_result(self, result: TextProcessingResult, ctx: WorkflowContext) -> None:\n",
    "        \"\"\"Collect results from sub-workflows.\"\"\"\n",
    "        print(f\"\ud83d\udce5 Collected result from {result.task_id}\")\n",
    "        self.results.append(result)\n",
    "\n",
    "        # Check if all results are collected\n",
    "        if len(self.results) == self.expected_count:\n",
    "            print(\"\\n\ud83c\udf89 All tasks completed!\")\n",
    "            await ctx.add_event(AllTasksCompleted(self.results))\n",
    "\n",
    "    def get_summary(self) -> dict[str, Any]:\n",
    "        \"\"\"Get a summary of all processing results.\"\"\"\n",
    "        total_words = sum(result.word_count for result in self.results)\n",
    "        total_chars = sum(result.char_count for result in self.results)\n",
    "        avg_words = total_words / len(self.results) if self.results else 0\n",
    "        avg_chars = total_chars / len(self.results) if self.results else 0\n",
    "\n",
    "        return {\n",
    "            \"total_texts\": len(self.results),\n",
    "            \"total_words\": total_words,\n",
    "            \"total_characters\": total_chars,\n",
    "            \"average_words_per_text\": round(avg_words, 2),\n",
    "            \"average_characters_per_text\": round(avg_chars, 2),\n",
    "        }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Wire everything together and run\n",
    "The `main()` coroutine creates both workflows, feeds sample texts, waits for completion, and prints a summary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    \"\"\"Main function to run the basic sub-workflow example.\"\"\"\n",
    "    print(\"\ud83d\ude80 Setting up sub-workflow...\")\n",
    "\n",
    "    # Step 1: Create the text processing sub-workflow\n",
    "    text_processor = TextProcessor()\n",
    "\n",
    "    processing_workflow = WorkflowBuilder().set_start_executor(text_processor).build()\n",
    "\n",
    "    print(\"\ud83d\udd27 Setting up parent workflow...\")\n",
    "\n",
    "    # Step 2: Create the parent workflow\n",
    "    orchestrator = TextProcessingOrchestrator()\n",
    "    workflow_executor = WorkflowExecutor(processing_workflow, id=\"text_processor_workflow\")\n",
    "\n",
    "    main_workflow = (\n",
    "        WorkflowBuilder()\n",
    "        .set_start_executor(orchestrator)\n",
    "        .add_edge(orchestrator, workflow_executor)\n",
    "        .add_edge(workflow_executor, orchestrator)\n",
    "        .build()\n",
    "    )\n",
    "\n",
    "    # Step 3: Test data - various text strings\n",
    "    test_texts = [\n",
    "        \"Hello world! This is a simple test.\",\n",
    "        \"Python is a powerful programming language used for many applications.\",\n",
    "        \"Short text.\",\n",
    "        \"This is a longer text with multiple sentences. It contains more words and characters. We use it to test our text processing workflow.\",  # noqa: E501\n",
    "        \"\",  # Empty string\n",
    "        \"   Spaces   around   text   \",\n",
    "    ]\n",
    "\n",
    "    print(f\"\\n\ud83e\uddea Testing with {len(test_texts)} text strings\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Step 4: Run the workflow\n",
    "    await main_workflow.run(test_texts)\n",
    "\n",
    "    # Step 5: Display results\n",
    "    print(\"\\n\ud83d\udcca Processing Results:\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Sort results by task_id for consistent display\n",
    "    sorted_results = sorted(orchestrator.results, key=lambda r: r.task_id)\n",
    "\n",
    "    for result in sorted_results:\n",
    "        preview = result.text[:30] + \"...\" if len(result.text) > 30 else result.text\n",
    "        preview = preview.replace(\"\\n\", \" \").strip() or \"(empty)\"\n",
    "        print(f\"\u2705 {result.task_id}: '{preview}' -> {result.word_count} words, {result.char_count} chars\")\n",
    "\n",
    "    # Step 6: Display summary\n",
    "    summary = orchestrator.get_summary()\n",
    "    print(\"\\n\ud83d\udcc8 Summary:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"\ud83d\udcc4 Total texts processed: {summary['total_texts']}\")\n",
    "    print(f\"\ud83d\udcdd Total words: {summary['total_words']}\")\n",
    "    print(f\"\ud83d\udd24 Total characters: {summary['total_characters']}\")\n",
    "    print(f\"\ud83d\udcca Average words per text: {summary['average_words_per_text']}\")\n",
    "    print(f\"\ud83d\udccf Average characters per text: {summary['average_characters_per_text']}\")\n",
    "\n",
    "    print(\"\\n\ud83c\udfc1 Processing complete!\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Try it yourself\n",
    "Use the helper below. In notebooks it awaits `main()` on the active loop; in scripts it falls back to `asyncio.run(main())`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "# Helper for notebooks vs. scripts\n",
    "loop = asyncio.get_event_loop()\n",
    "if loop.is_running():\n",
    "    # Jupyter/VS Code notebooks already have an event loop, so await directly.\n",
    "    await main()\n",
    "else:\n",
    "    asyncio.run(main())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
