{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# checkpoint_with_human_in_the_loop.py - ELI5 Walkthrough\n",
    "This notebook gives a friendly tour of `python/samples/getting_started/workflows/checkpoint/checkpoint_with_human_in_the_loop.py`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big Picture\n",
    "Think of a relay race between an AI copywriter and a human reviewer. The workflow drafts release notes, pauses for human approval, and can be stopped and resumed later because every superstep is checkpointed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Ingredients\n",
    "- `WorkflowBuilder` wires a tiny graph: prepare brief -> writer -> review gateway -> human -> finalise.\n",
    "- `RequestInfoExecutor` pauses the run until a human provides guidance.\n",
    "- `FileCheckpointStorage` keeps JSON snapshots so a later process can resume.\n",
    "- Helper utilities print checkpoint summaries and replay events for humans.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow Diagram\n",
    "```mermaid\n",
    "flowchart LR\n",
    "    Start([\"Marketing Brief\"]) --> Prepare[[BriefPreparer]]\n",
    "    Prepare --> Writer[[Writer Agent]]\n",
    "    Writer --> Gateway[[ReviewGateway]]\n",
    "    Gateway --> RequestInfo[/RequestInfoExecutor/]\n",
    "    RequestInfo --> Human[\"Human Reviewer\"]\n",
    "    Human --> Gateway\n",
    "    Gateway --> Writer\n",
    "    Gateway --> Final[[FinaliseExecutor]]\n",
    "    Final --> Output([\"Approved Copy\"])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Configure the environment and checkpoint storage\n",
    "Load environment variables, import the Agent Framework pieces we need, and create a temporary folder inside the workspace so checkpoints land somewhere predictable for this notebook run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Microsoft. All rights reserved.\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import asyncio\n",
    "from collections.abc import AsyncIterable\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import TYPE_CHECKING, Any\n",
    "\n",
    "from agent_framework import (\n",
    "    AgentExecutor,\n",
    "    AgentExecutorRequest,\n",
    "    AgentExecutorResponse,\n",
    "    ChatMessage,\n",
    "    Executor,\n",
    "    FileCheckpointStorage,\n",
    "    RequestInfoEvent,\n",
    "    RequestInfoExecutor,\n",
    "    RequestInfoMessage,\n",
    "    RequestResponse,\n",
    "    Role,\n",
    "    WorkflowBuilder,\n",
    "    WorkflowContext,\n",
    "    WorkflowOutputEvent,\n",
    "    WorkflowRunState,\n",
    "    WorkflowStatusEvent,\n",
    "    handler,\n",
    ")\n",
    "from agent_framework.azure import AzureOpenAIChatClient\n",
    "from azure.identity import AzureCliCredential\n",
    "\n",
    "# NOTE: the Azure client imports above are real dependencies. When running this\n",
    "# sample outside of Azure-enabled environments you may wish to swap in the\n",
    "# `agent_framework.builtin` chat client or mock the writer executor. We keep the\n",
    "# concrete import here so readers can see an end-to-end configuration.\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from agent_framework import Workflow\n",
    "    from agent_framework._workflows._checkpoint import WorkflowCheckpoint\n",
    "\n",
    "\"\"\"\n",
    "Sample: Checkpoint + human-in-the-loop quickstart.\n",
    "\n",
    "This getting-started sample keeps the moving pieces to a minimum:\n",
    "\n",
    "1. A brief is turned into a consistent prompt for an AI copywriter.\n",
    "2. The copywriter (an `AgentExecutor`) drafts release notes.\n",
    "3. A reviewer gateway routes every draft through `RequestInfoExecutor` so a human\n",
    "   can approve or request tweaks.\n",
    "4. The workflow records checkpoints between each superstep so you can stop the\n",
    "   program, restart later, and optionally pre-supply human answers on resume.\n",
    "\n",
    "Key concepts demonstrated\n",
    "-------------------------\n",
    "- Minimal executor pipeline with checkpoint persistence.\n",
    "- Human-in-the-loop pause/resume by pairing `RequestInfoExecutor` with\n",
    "  checkpoint restoration.\n",
    "- Supplying responses at restore time (`run_stream_from_checkpoint(..., responses=...)`).\n",
    "\n",
    "Typical pause/resume flow\n",
    "-------------------------\n",
    "1. Run the workflow until a human approval request is emitted.\n",
    "2. If the human is offline, exit the program. A checkpoint with\n",
    "   ``status=awaiting human response`` now exists.\n",
    "3. Later, restart the script, select that checkpoint, and provide the stored\n",
    "   human decision when prompted to pre-supply responses.\n",
    "   Doing so applies the answer immediately on resume, so the system does **not**\n",
    "   re-emit the same `RequestInfoEvent`.\n",
    "\"\"\"\n",
    "\n",
    "# Directory used for the sample's temporary checkpoint files. We isolate the\n",
    "# demo artefacts so that repeated runs do not collide with other samples and so\n",
    "# the clean-up step at the end of the script can simply delete the directory.\n",
    "TEMP_DIR = Path.cwd() / \"eli5_tmp\" / \"checkpoints_hitl\"\n",
    "TEMP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Define the authoring and review executors\n",
    "These classes turn a marketing brief into drafts, route each draft through a human reviewer, and publish the approved copy. Everything is encapsulated so executor state can be checkpointed cleanly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BriefPreparer(Executor):\n",
    "    \"\"\"Normalises the user brief and sends a single AgentExecutorRequest.\"\"\"\n",
    "\n",
    "    # The first executor in the workflow. By keeping it tiny we make it easier\n",
    "    # to reason about the state that will later be captured in the checkpoint.\n",
    "    # It is responsible for tidying the human-provided brief and kicking off the\n",
    "    # agent run with a deterministic prompt structure.\n",
    "\n",
    "    def __init__(self, id: str, agent_id: str) -> None:\n",
    "        super().__init__(id=id)\n",
    "        self._agent_id = agent_id\n",
    "\n",
    "    @handler\n",
    "    async def prepare(self, brief: str, ctx: WorkflowContext[AgentExecutorRequest, str]) -> None:\n",
    "        # Collapse errant whitespace so the prompt is stable between runs.\n",
    "        normalized = \" \".join(brief.split()).strip()\n",
    "        if not normalized.endswith(\".\"):\n",
    "            normalized += \".\"\n",
    "        # Persist the cleaned brief in shared state so downstream executors and\n",
    "        # future checkpoints can recover the original intent.\n",
    "        await ctx.set_shared_state(\"brief\", normalized)\n",
    "        prompt = (\n",
    "            \"You are drafting product release notes. Summarise the brief below in two sentences. \"\n",
    "            \"Keep it positive and end with a call to action.\\n\\n\"\n",
    "            f\"BRIEF: {normalized}\"\n",
    "        )\n",
    "        # Hand the prompt to the writer agent. We always route through the\n",
    "        # workflow context so the runtime can capture messages for checkpointing.\n",
    "        await ctx.send_message(\n",
    "            AgentExecutorRequest(messages=[ChatMessage(Role.USER, text=prompt)], should_respond=True),\n",
    "            target_id=self._agent_id,\n",
    "        )\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class HumanApprovalRequest(RequestInfoMessage):\n",
    "    \"\"\"Message sent to the human reviewer via RequestInfoExecutor.\"\"\"\n",
    "\n",
    "    # These fields are intentionally simple because they are serialised into\n",
    "    # checkpoints. Keeping them primitive types guarantees the new\n",
    "    # `pending_requests_from_checkpoint` helper can reconstruct them on resume.\n",
    "    prompt: str = \"\"\n",
    "    draft: str = \"\"\n",
    "    iteration: int = 0\n",
    "\n",
    "\n",
    "class ReviewGateway(Executor):\n",
    "    \"\"\"Routes agent drafts to humans and optionally back for revisions.\"\"\"\n",
    "\n",
    "    def __init__(self, id: str, reviewer_id: str, writer_id: str, finalize_id: str) -> None:\n",
    "        super().__init__(id=id)\n",
    "        self._reviewer_id = reviewer_id\n",
    "        self._writer_id = writer_id\n",
    "        self._finalize_id = finalize_id\n",
    "\n",
    "    @handler\n",
    "    async def on_agent_response(\n",
    "        self,\n",
    "        response: AgentExecutorResponse,\n",
    "        ctx: WorkflowContext[HumanApprovalRequest, str],\n",
    "    ) -> None:\n",
    "        # Capture the agent output so we can surface it to the reviewer and\n",
    "        # persist iterations. The `RequestInfoExecutor` relies on this state to\n",
    "        # rehydrate when checkpoints are restored.\n",
    "        draft = response.agent_run_response.text or \"\"\n",
    "        iteration = int((await ctx.get_state() or {}).get(\"iteration\", 0)) + 1\n",
    "        await ctx.set_state({\"iteration\": iteration, \"last_draft\": draft})\n",
    "        # Emit a human approval request. Because this flows through\n",
    "        # RequestInfoExecutor it will pause the workflow until an answer is\n",
    "        # supplied either interactively or via pre-supplied responses.\n",
    "        await ctx.send_message(\n",
    "            HumanApprovalRequest(\n",
    "                prompt=\"Review the draft. Reply 'approve' or provide edit instructions.\",\n",
    "                draft=draft,\n",
    "                iteration=iteration,\n",
    "            ),\n",
    "            target_id=self._reviewer_id,\n",
    "        )\n",
    "\n",
    "    @handler\n",
    "    async def on_human_feedback(\n",
    "        self,\n",
    "        feedback: RequestResponse[HumanApprovalRequest, str],\n",
    "        ctx: WorkflowContext[AgentExecutorRequest | str, str],\n",
    "    ) -> None:\n",
    "        # The RequestResponse wrapper gives us both the human data and the\n",
    "        # original request message, even when resuming from checkpoints.\n",
    "        reply = (feedback.data or \"\").strip()\n",
    "        state = await ctx.get_state() or {}\n",
    "        draft = state.get(\"last_draft\") or (feedback.original_request.draft if feedback.original_request else \"\")\n",
    "\n",
    "        if reply.lower() == \"approve\":\n",
    "            # When the human signs off we can short-circuit the workflow and\n",
    "            # send the approved draft to the final executor.\n",
    "            await ctx.send_message(draft, target_id=self._finalize_id)\n",
    "            return\n",
    "\n",
    "        # Any other response loops us back to the writer with fresh guidance.\n",
    "        guidance = reply or \"Tighten the copy and emphasise customer benefit.\"\n",
    "        iteration = int(state.get(\"iteration\", 1)) + 1\n",
    "        await ctx.set_state({\"iteration\": iteration, \"last_draft\": draft})\n",
    "        prompt = (\n",
    "            \"Revise the launch note. Respond with the new copy only.\\n\\n\"\n",
    "            f\"Previous draft:\\n{draft}\\n\\n\"\n",
    "            f\"Human guidance: {guidance}\"\n",
    "        )\n",
    "        await ctx.send_message(\n",
    "            AgentExecutorRequest(messages=[ChatMessage(Role.USER, text=prompt)], should_respond=True),\n",
    "            target_id=self._writer_id,\n",
    "        )\n",
    "\n",
    "\n",
    "class FinaliseExecutor(Executor):\n",
    "    \"\"\"Publishes the approved text.\"\"\"\n",
    "\n",
    "    @handler\n",
    "    async def publish(self, text: str, ctx: WorkflowContext[Any, str]) -> None:\n",
    "        # Store the output so diagnostics or a UI could fetch the final copy.\n",
    "        await ctx.set_state({\"published_text\": text})\n",
    "        # Yield the final output so the workflow completes cleanly.\n",
    "        await ctx.yield_output(text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Wire the workflow graph\n",
    "`create_workflow` instantiates the Azure agents, wraps them in executors, and connects every edge. When checkpoint storage is supplied the builder enables persistence automatically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_workflow(*, checkpoint_storage: FileCheckpointStorage | None = None) -> \"Workflow\":\n",
    "    \"\"\"Assemble the workflow graph used by both the initial run and resume.\"\"\"\n",
    "\n",
    "    # The Azure client is created once so our agent executor can issue calls to\n",
    "    # the hosted model. The agent id is stable across runs which keeps\n",
    "    # checkpoints deterministic.\n",
    "    chat_client = AzureOpenAIChatClient(credential=AzureCliCredential())\n",
    "    writer = AgentExecutor(\n",
    "        chat_client.create_agent(\n",
    "            instructions=\"Write concise, warm release notes that sound human and helpful.\",\n",
    "        ),\n",
    "        id=\"writer\",\n",
    "    )\n",
    "    # RequestInfoExecutor is the lynchpin for human-in-the-loop: every draft is\n",
    "    # routed through it so checkpoints can pause while waiting for responses.\n",
    "    review = RequestInfoExecutor(id=\"request_info\")\n",
    "    finalise = FinaliseExecutor(id=\"finalise\")\n",
    "    gateway = ReviewGateway(\n",
    "        id=\"review_gateway\",\n",
    "        reviewer_id=review.id,\n",
    "        writer_id=writer.id,\n",
    "        finalize_id=finalise.id,\n",
    "    )\n",
    "    prepare = BriefPreparer(id=\"prepare_brief\", agent_id=writer.id)\n",
    "\n",
    "    # Wire the workflow DAG. Edges mirror the numbered steps described in the\n",
    "    # module docstring. Because `WorkflowBuilder` is declarative, reading these\n",
    "    # edges is often the quickest way to understand execution order.\n",
    "    builder = (\n",
    "        WorkflowBuilder(max_iterations=6)\n",
    "        .set_start_executor(prepare)\n",
    "        .add_edge(prepare, writer)\n",
    "        .add_edge(writer, gateway)\n",
    "        .add_edge(gateway, review)\n",
    "        .add_edge(review, gateway)  # human resumes loop\n",
    "        .add_edge(gateway, writer)  # revisions\n",
    "        .add_edge(gateway, finalise)\n",
    "    )\n",
    "    # Opt-in to persistence when the caller provides storage. The workflow\n",
    "    # object itself is identical whether or not checkpointing is enabled.\n",
    "    if checkpoint_storage:\n",
    "        builder = builder.with_checkpointing(checkpoint_storage=checkpoint_storage)\n",
    "    return builder.build()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Helper utilities for checkpoints and events\n",
    "Utility functions format checkpoint summaries, echo workflow events, and gather human responses. Keeping them separate keeps the main run loop readable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _render_checkpoint_summary(checkpoints: list[\"WorkflowCheckpoint\"]) -> None:\n",
    "    \"\"\"Pretty-print saved checkpoints with the new framework summaries.\"\"\"\n",
    "\n",
    "    print(\"\\nCheckpoint summary:\")\n",
    "    for summary in [\n",
    "        RequestInfoExecutor.checkpoint_summary(cp) for cp in sorted(checkpoints, key=lambda c: c.timestamp)\n",
    "    ]:\n",
    "        # Compose a single line per checkpoint so the user can scan the output\n",
    "        # and pick the resume point that still has outstanding human work.\n",
    "        line = (\n",
    "            f\"- {summary.checkpoint_id} | iter={summary.iteration_count} \"\n",
    "            f\"| targets={summary.targets} | states={summary.executor_states}\"\n",
    "        )\n",
    "        if summary.status:\n",
    "            line += f\" | status={summary.status}\"\n",
    "        if summary.draft_preview:\n",
    "            line += f\" | draft_preview={summary.draft_preview}\"\n",
    "        if summary.pending_requests:\n",
    "            line += f\" | pending_request_id={summary.pending_requests[0].request_id}\"\n",
    "        print(line)\n",
    "\n",
    "\n",
    "def _print_events(events: list[Any]) -> tuple[str | None, list[tuple[str, HumanApprovalRequest]]]:\n",
    "    \"\"\"Echo workflow events to the console and collect outstanding requests.\"\"\"\n",
    "\n",
    "    completed_output: str | None = None\n",
    "    requests: list[tuple[str, HumanApprovalRequest]] = []\n",
    "\n",
    "    for event in events:\n",
    "        print(f\"Event: {event}\")\n",
    "        if isinstance(event, WorkflowOutputEvent):\n",
    "            completed_output = event.data\n",
    "        if isinstance(event, RequestInfoEvent) and isinstance(event.data, HumanApprovalRequest):\n",
    "            # Capture pending human approvals so the caller can ask the user for\n",
    "            # input after the current batch of events is processed.\n",
    "            requests.append((event.request_id, event.data))\n",
    "        elif isinstance(event, WorkflowStatusEvent) and event.state in {\n",
    "            WorkflowRunState.IN_PROGRESS_PENDING_REQUESTS,\n",
    "            WorkflowRunState.IDLE_WITH_PENDING_REQUESTS,\n",
    "        }:\n",
    "            print(f\"Workflow state: {event.state.name}\")\n",
    "\n",
    "    return completed_output, requests\n",
    "\n",
    "\n",
    "def _prompt_for_responses(requests: list[tuple[str, HumanApprovalRequest]]) -> dict[str, str] | None:\n",
    "    \"\"\"Interactive CLI prompt for any live RequestInfo requests.\"\"\"\n",
    "\n",
    "    if not requests:\n",
    "        return None\n",
    "    answers: dict[str, str] = {}\n",
    "    for request_id, request in requests:\n",
    "        # Keep the prompt conversational so testers can use the script without\n",
    "        # memorising the workflow APIs.\n",
    "        print(\"\\n=== Human approval needed ===\")\n",
    "        print(f\"request_id: {request_id}\")\n",
    "        if request.iteration:\n",
    "            print(f\"Iteration: {request.iteration}\")\n",
    "        print(request.prompt)\n",
    "        print(\"Draft: \\n---\\n\" + request.draft + \"\\n---\")\n",
    "        answer = input(\"Type 'approve' or enter revision guidance (or 'exit' to quit): \").strip()  # noqa: ASYNC250\n",
    "        if answer.lower() == \"exit\":\n",
    "            raise SystemExit(\"Stopped by user.\")\n",
    "        answers[request_id] = answer\n",
    "    return answers\n",
    "\n",
    "\n",
    "def _maybe_pre_supply_responses(cp: \"WorkflowCheckpoint\") -> dict[str, str] | None:\n",
    "    \"\"\"Offer to collect responses before resuming a checkpoint.\"\"\"\n",
    "\n",
    "    pending = RequestInfoExecutor.pending_requests_from_checkpoint(cp)\n",
    "    if not pending:\n",
    "        return None\n",
    "\n",
    "    print(\n",
    "        \"This checkpoint still has pending human input. Provide the responses now so the resume step \"\n",
    "        \"applies them immediately and does not re-emit the original RequestInfo event.\"\n",
    "    )\n",
    "    choice = input(\"Pre-supply responses for this checkpoint? [y/N]: \").strip().lower()  # noqa: ASYNC250\n",
    "    if choice not in {\"y\", \"yes\"}:\n",
    "        return None\n",
    "\n",
    "    answers: dict[str, str] = {}\n",
    "    for item in pending:\n",
    "        iteration = item.iteration or 0\n",
    "        print(f\"\\nPending draft (iteration {iteration} | request_id={item.request_id}):\")\n",
    "        draft_text = (item.draft or \"\").strip()\n",
    "        if draft_text:\n",
    "            # The shortened preview in the summary may truncate text; here we\n",
    "            # show the full draft so the reviewer can make an informed choice.\n",
    "            print(\"Draft:\\n---\\n\" + draft_text + \"\\n---\")\n",
    "        else:\n",
    "            print(\"Draft: [not captured in checkpoint payload - refer to your notes/log]\")\n",
    "        prompt_text = (item.prompt or \"Review the draft\").strip()\n",
    "        print(prompt_text)\n",
    "        answer = input(\"Response ('approve' or guidance, 'exit' to abort): \").strip()  # noqa: ASYNC250\n",
    "        if answer.lower() == \"exit\":\n",
    "            raise SystemExit(\"Resume aborted by user.\")\n",
    "        answers[item.request_id] = answer\n",
    "    return answers\n",
    "\n",
    "\n",
    "async def _consume(stream: AsyncIterable[Any]) -> list[Any]:\n",
    "    \"\"\"Materialise an async event stream into a list.\"\"\"\n",
    "\n",
    "    return [event async for event in stream]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Orchestrate interactive runs and resumes\n",
    "`run_interactive_session` drives the initial run until it pauses, and `resume_from_checkpoint` restores a saved state while optionally injecting pre-supplied human answers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_interactive_session(workflow: \"Workflow\", initial_message: str) -> str | None:\n",
    "    \"\"\"Run the workflow until it either finishes or pauses for human input.\"\"\"\n",
    "\n",
    "    pending_responses: dict[str, str] | None = None\n",
    "    completed_output: str | None = None\n",
    "    first = True\n",
    "\n",
    "    while completed_output is None:\n",
    "        if first:\n",
    "            # Kick off the workflow with the initial brief. The returned events\n",
    "            # include RequestInfo events when the agent produces a draft.\n",
    "            events = await _consume(workflow.run_stream(initial_message))\n",
    "            first = False\n",
    "        elif pending_responses:\n",
    "            # Feed any answers the user just typed back into the workflow.\n",
    "            events = await _consume(workflow.send_responses_streaming(pending_responses))\n",
    "        else:\n",
    "            break\n",
    "\n",
    "        completed_output, requests = _print_events(events)\n",
    "        if completed_output is None:\n",
    "            pending_responses = _prompt_for_responses(requests)\n",
    "\n",
    "    return completed_output\n",
    "\n",
    "\n",
    "async def resume_from_checkpoint(\n",
    "    workflow: \"Workflow\",\n",
    "    checkpoint_id: str,\n",
    "    storage: FileCheckpointStorage,\n",
    "    pre_supplied: dict[str, str] | None,\n",
    ") -> None:\n",
    "    \"\"\"Resume a stored checkpoint and continue until completion or another pause.\"\"\"\n",
    "\n",
    "    print(f\"\\nResuming from checkpoint: {checkpoint_id}\")\n",
    "    events = await _consume(\n",
    "        workflow.run_stream_from_checkpoint(\n",
    "            checkpoint_id,\n",
    "            checkpoint_storage=storage,\n",
    "            responses=pre_supplied,\n",
    "        )\n",
    "    )\n",
    "    completed_output, requests = _print_events(events)\n",
    "    if pre_supplied and not requests and completed_output is None:\n",
    "        # When the checkpoint only needed the provided answers we let the user\n",
    "        # know the workflow is waiting for the next superstep (usually another\n",
    "        # agent response).\n",
    "        print(\"Pre-supplied responses applied automatically; workflow is now waiting for the next step.\")\n",
    "\n",
    "    pending = _prompt_for_responses(requests)\n",
    "    while completed_output is None and pending:\n",
    "        events = await _consume(workflow.send_responses_streaming(pending))\n",
    "        completed_output, requests = _print_events(events)\n",
    "        if completed_output is None:\n",
    "            pending = _prompt_for_responses(requests)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    if completed_output:\n",
    "        print(f\"Workflow completed with: {completed_output}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Tie everything together\n",
    "The `main` coroutine cleans old checkpoints, runs the workflow, lets you pick a checkpoint, and then shows how to resume it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main() -> None:\n",
    "    \"\"\"Entry point used by both the initial run and subsequent resumes.\"\"\"\n",
    "\n",
    "    for file in TEMP_DIR.glob(\"*.json\"):\n",
    "        # Start each execution with a clean slate so the demonstration is\n",
    "        # deterministic even if the directory had stale checkpoints.\n",
    "        file.unlink()\n",
    "\n",
    "    storage = FileCheckpointStorage(storage_path=TEMP_DIR)\n",
    "    workflow = create_workflow(checkpoint_storage=storage)\n",
    "\n",
    "    brief = (\n",
    "        \"Introduce our limited edition smart coffee grinder. Mention the $249 price, highlight the \"\n",
    "        \"sensor that auto-adjusts the grind, and invite customers to pre-order on the website.\"\n",
    "    )\n",
    "\n",
    "    print(\"Running workflow (human approval required)...\")\n",
    "    completed = await run_interactive_session(workflow, initial_message=brief)\n",
    "    if completed:\n",
    "        print(f\"Initial run completed with final copy: {completed}\")\n",
    "    else:\n",
    "        print(\"Initial run paused for human input.\")\n",
    "\n",
    "    checkpoints = await storage.list_checkpoints()\n",
    "    if not checkpoints:\n",
    "        print(\"No checkpoints recorded.\")\n",
    "        return\n",
    "\n",
    "    # Show the user what is available before we prompt for the index. The\n",
    "    # summary helper keeps this output consistent with other tooling.\n",
    "    _render_checkpoint_summary(checkpoints)\n",
    "\n",
    "    sorted_cps = sorted(checkpoints, key=lambda c: c.timestamp)\n",
    "    print(\"\\nAvailable checkpoints:\")\n",
    "    for idx, cp in enumerate(sorted_cps):\n",
    "        print(f\"  [{idx}] id={cp.checkpoint_id} iter={cp.iteration_count}\")\n",
    "\n",
    "    # For the pause/resume demo we typically pick the latest checkpoint whose summary\n",
    "    # status reads \"awaiting human response\" - that is the saved state that proves the\n",
    "    # workflow can rehydrate, collect the pending answer, and continue after a break.\n",
    "    selection = input(\"\\nResume from which checkpoint? (press Enter to skip): \").strip()  # noqa: ASYNC250\n",
    "    if not selection:\n",
    "        print(\"No resume selected. Exiting.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        idx = int(selection)\n",
    "    except ValueError:\n",
    "        print(\"Invalid input; exiting.\")\n",
    "        return\n",
    "\n",
    "    if not 0 <= idx < len(sorted_cps):\n",
    "        print(\"Index out of range; exiting.\")\n",
    "        return\n",
    "\n",
    "    chosen = sorted_cps[idx]\n",
    "    summary = RequestInfoExecutor.checkpoint_summary(chosen)\n",
    "    if summary.status == \"completed\":\n",
    "        print(\"Selected checkpoint already reflects a completed workflow; nothing to resume.\")\n",
    "        return\n",
    "\n",
    "    # If the user wants, capture their decisions now so the resume call can\n",
    "    # push them into the workflow and avoid re-prompting.\n",
    "    pre_responses = _maybe_pre_supply_responses(chosen)\n",
    "\n",
    "    resumed_workflow = create_workflow()\n",
    "    # Resume with a fresh workflow instance. The checkpoint carries the\n",
    "    # persistent state while this object holds the runtime wiring.\n",
    "    await resume_from_checkpoint(resumed_workflow, chosen.checkpoint_id, storage, pre_responses)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step ??: Try it yourself\n",
    "Use the helper below. In notebooks it awaits `main()` on the active loop; in scripts it falls back to `asyncio.run(main())`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "# Helper for notebooks vs. scripts\n",
    "loop = asyncio.get_event_loop()\n",
    "if loop.is_running():\n",
    "    # Jupyter/VS Code notebooks already have an event loop, so await directly.\n",
    "    await main()\n",
    "else:\n",
    "    asyncio.run(main())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
