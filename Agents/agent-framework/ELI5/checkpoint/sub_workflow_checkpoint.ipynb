{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sub_workflow_checkpoint.py - ELI5 Walkthrough\n",
    "This notebook recreates `python/samples/getting_started/workflows/checkpoint/sub_workflow_checkpoint.py` in place so you can study it without referencing the .py file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big Picture\n",
    "A parent workflow delegates drafting work to a sub-workflow. The sub-workflow pauses for human review, the parent persists checkpoints, and later you can resume with the human decision already supplied.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Ingredients\n",
    "- Data classes describe the messages passed between parent, sub-workflow, and human reviewers.\n",
    "- The sub-workflow uses `RequestInfoExecutor` to surface human approval.\n",
    "- The parent workflow wraps the sub-workflow with `WorkflowExecutor` and writes checkpoints.\n",
    "- Resume logic reads the pending request from storage and injects the approval automatically.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow Diagram\n",
    "```mermaid\n",
    "flowchart LR\n",
    "    Start([\"Launch Topic\"]) --> Coordinator[[LaunchCoordinator]]\n",
    "    Coordinator --> SubExec[[WorkflowExecutor]]\n",
    "    subgraph SubWorkflow\n",
    "        WriterNode[[DraftWriter]] --> Router[[DraftReviewRouter]]\n",
    "        Router --> SubReq[/RequestInfoExecutor/]\n",
    "        SubReq --> Router\n",
    "        Router --> Finaliser[[DraftFinaliser]]\n",
    "    end\n",
    "    SubExec --> ParentReq[/Parent RequestInfoExecutor/]\n",
    "    ParentReq --> SubExec\n",
    "    SubExec --> Coordinator\n",
    "    Coordinator --> Output([\"Final Draft\"])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Configure imports and checkpoint location\n",
    "Bring in the workflow primitives and point checkpoint storage at a workspace-local directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Microsoft. All rights reserved.\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import asyncio\n",
    "import contextlib\n",
    "import json\n",
    "from dataclasses import dataclass, field, replace\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "from agent_framework import (\n",
    "    Executor,\n",
    "    FileCheckpointStorage,\n",
    "    RequestInfoEvent,\n",
    "    RequestInfoExecutor,\n",
    "    RequestInfoMessage,\n",
    "    RequestResponse,\n",
    "    Workflow,\n",
    "    WorkflowBuilder,\n",
    "    WorkflowContext,\n",
    "    WorkflowExecutor,\n",
    "    WorkflowOutputEvent,\n",
    "    WorkflowRunState,\n",
    "    WorkflowStatusEvent,\n",
    "    handler,\n",
    ")\n",
    "\n",
    "CHECKPOINT_DIR = Path.cwd() / \"eli5_tmp\" / \"sub_workflow_checkpoints\"\n",
    "\n",
    "\"\"\"\n",
    "Sample: Checkpointing for workflows that embed sub-workflows.\n",
    "\n",
    "This sample shows how a parent workflow that wraps a sub-workflow can:\n",
    "- run until the sub-workflow emits a human approval request via RequestInfoExecutor\n",
    "- persist a checkpoint that captures the pending request (including complex payloads)\n",
    "- resume later, supplying the human decision directly at restore time\n",
    "\n",
    "It is intentionally similar in spirit to the orchestration checkpoint sample but\n",
    "uses ``WorkflowExecutor`` so we exercise the full parent/sub-workflow round-trip.\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Describe the payloads shared between stages\n",
    "Helper functions and dataclasses define what the parent, sub-workflow, and human reviewer pass around.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _utc_now() -> datetime:\n",
    "    return datetime.now()\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Messages exchanged inside the sub-workflow\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DraftTask:\n",
    "    \"\"\"Task handed from the parent to the sub-workflow writer.\"\"\"\n",
    "\n",
    "    topic: str\n",
    "    due: datetime\n",
    "    iteration: int = 1\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DraftPackage:\n",
    "    \"\"\"Intermediate draft produced by the sub-workflow writer.\"\"\"\n",
    "\n",
    "    topic: str\n",
    "    content: str\n",
    "    iteration: int\n",
    "    created_at: datetime = field(default_factory=_utc_now)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class FinalDraft:\n",
    "    \"\"\"Final deliverable returned to the parent workflow.\"\"\"\n",
    "\n",
    "    topic: str\n",
    "    content: str\n",
    "    iterations: int\n",
    "    approved_at: datetime\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ReviewRequest(RequestInfoMessage):\n",
    "    \"\"\"Human approval request surfaced via RequestInfoExecutor.\"\"\"\n",
    "\n",
    "    topic: str = \"\"\n",
    "    iteration: int = 1\n",
    "    draft_excerpt: str = \"\"\n",
    "    due_iso: str = \"\"\n",
    "    reviewer_guidance: list[str] = field(default_factory=list)  # type: ignore\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Sub-workflow executors\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Build the sub-workflow executors\n",
    "The sub-workflow drafts copy, raises human approval requests, and loops until a final draft is approved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DraftWriter(Executor):\n",
    "    \"\"\"Produces an initial draft for the supplied topic.\"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__(id=\"draft_writer\")\n",
    "\n",
    "    @handler\n",
    "    async def create_draft(self, task: DraftTask, ctx: WorkflowContext[DraftPackage]) -> None:\n",
    "        draft = DraftPackage(\n",
    "            topic=task.topic,\n",
    "            content=(\n",
    "                f\"Launch plan for {task.topic}.\\n\\n\"\n",
    "                \"- Outline the customer message.\\n\"\n",
    "                \"- Highlight three differentiators.\\n\"\n",
    "                \"- Close with a next-step CTA.\\n\"\n",
    "                f\"(iteration {task.iteration})\"\n",
    "            ),\n",
    "            iteration=task.iteration,\n",
    "        )\n",
    "        await ctx.send_message(draft, target_id=\"draft_review\")\n",
    "\n",
    "\n",
    "class DraftReviewRouter(Executor):\n",
    "    \"\"\"Turns draft packages into human approval requests.\"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__(id=\"draft_review\")\n",
    "\n",
    "    @handler\n",
    "    async def request_review(self, draft: DraftPackage, ctx: WorkflowContext[ReviewRequest]) -> None:\n",
    "        excerpt = draft.content.splitlines()[0]\n",
    "        request = ReviewRequest(\n",
    "            topic=draft.topic,\n",
    "            iteration=draft.iteration,\n",
    "            draft_excerpt=excerpt,\n",
    "            due_iso=draft.created_at.isoformat(),\n",
    "            reviewer_guidance=[\n",
    "                \"Ensure tone matches launch messaging\",\n",
    "                \"Confirm CTA is action-oriented\",\n",
    "            ],\n",
    "        )\n",
    "        await ctx.send_message(request, target_id=\"sub_review_requests\")\n",
    "\n",
    "    @handler\n",
    "    async def forward_decision(\n",
    "        self,\n",
    "        decision: RequestResponse[ReviewRequest, str],\n",
    "        ctx: WorkflowContext[RequestResponse[ReviewRequest, str]],\n",
    "    ) -> None:\n",
    "        await ctx.send_message(decision, target_id=\"draft_finaliser\")\n",
    "\n",
    "\n",
    "class DraftFinaliser(Executor):\n",
    "    \"\"\"Applies the human decision and emits the final draft.\"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__(id=\"draft_finaliser\")\n",
    "\n",
    "    @handler\n",
    "    async def on_review_decision(\n",
    "        self,\n",
    "        decision: RequestResponse[ReviewRequest, str],\n",
    "        ctx: WorkflowContext[DraftTask, FinalDraft],\n",
    "    ) -> None:\n",
    "        reply = (decision.data or \"\").strip().lower()\n",
    "        original = decision.original_request\n",
    "        topic = original.topic if original else \"unknown topic\"\n",
    "        iteration = original.iteration if original else 1\n",
    "\n",
    "        if reply != \"approve\":\n",
    "            # Loop back with a follow-up task. In a real workflow you would\n",
    "            # incorporate the human guidance; here we just increment the counter.\n",
    "            next_task = DraftTask(\n",
    "                topic=topic,\n",
    "                due=_utc_now() + timedelta(hours=1),\n",
    "                iteration=iteration + 1,\n",
    "            )\n",
    "            await ctx.send_message(next_task, target_id=\"draft_writer\")\n",
    "            return\n",
    "\n",
    "        final = FinalDraft(\n",
    "            topic=topic,\n",
    "            content=f\"Approved launch narrative for {topic} (iteration {iteration}).\",\n",
    "            iterations=iteration,\n",
    "            approved_at=_utc_now(),\n",
    "        )\n",
    "        await ctx.yield_output(final)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Parent workflow executors\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Coordinate the parent workflow\n",
    "`LaunchCoordinator` kicks off the sub-workflow and captures the final approved draft for reporting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaunchCoordinator(Executor):\n",
    "    \"\"\"Owns the top-level workflow and collects the final draft.\"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__(id=\"launch_coordinator\")\n",
    "        self._final: FinalDraft | None = None\n",
    "\n",
    "    @handler\n",
    "    async def kick_off(self, topic: str, ctx: WorkflowContext[DraftTask]) -> None:\n",
    "        task = DraftTask(topic=topic, due=_utc_now() + timedelta(hours=2))\n",
    "        await ctx.send_message(task, target_id=\"launch_subworkflow\")\n",
    "\n",
    "    @handler\n",
    "    async def collect_final(self, draft: FinalDraft, ctx: WorkflowContext[None, FinalDraft]) -> None:\n",
    "        approved_at = draft.approved_at\n",
    "        normalised = draft\n",
    "        if isinstance(approved_at, str):\n",
    "            with contextlib.suppress(ValueError):\n",
    "                parsed = datetime.fromisoformat(approved_at)\n",
    "                normalised = replace(draft, approved_at=parsed)\n",
    "                approved_at = parsed\n",
    "\n",
    "        self._final = normalised\n",
    "\n",
    "        approved_display = approved_at.isoformat() if hasattr(approved_at, \"isoformat\") else str(approved_at)\n",
    "\n",
    "        print(\"\\n>>> Parent workflow received approved draft:\")\n",
    "        print(f\"- Topic: {normalised.topic}\")\n",
    "        print(f\"- Iterations: {normalised.iterations}\")\n",
    "        print(f\"- Approved at: {approved_display}\")\n",
    "        print(f\"- Content: {normalised.content}\\n\")\n",
    "\n",
    "        await ctx.yield_output(normalised)\n",
    "\n",
    "    @property\n",
    "    def final_result(self) -> FinalDraft | None:\n",
    "        return self._final\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Workflow construction helpers\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Assemble parent and sub-workflows\n",
    "Helper functions build the inner workflow, wrap it in `WorkflowExecutor`, and stitch everything together with checkpointing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sub_workflow() -> WorkflowExecutor:\n",
    "    writer = DraftWriter()\n",
    "    router = DraftReviewRouter()\n",
    "    request_info = RequestInfoExecutor(id=\"sub_review_requests\")\n",
    "    finaliser = DraftFinaliser()\n",
    "\n",
    "    sub_workflow = (\n",
    "        WorkflowBuilder()\n",
    "        .set_start_executor(writer)\n",
    "        .add_edge(writer, router)\n",
    "        .add_edge(router, request_info)\n",
    "        .add_edge(request_info, router, condition=lambda msg: isinstance(msg, RequestResponse))\n",
    "        .add_edge(router, finaliser, condition=lambda msg: isinstance(msg, RequestResponse))\n",
    "        .add_edge(request_info, finaliser)\n",
    "        .add_edge(finaliser, writer)  # permits revision loops\n",
    "        .build()\n",
    "    )\n",
    "\n",
    "    return WorkflowExecutor(sub_workflow, id=\"launch_subworkflow\")\n",
    "\n",
    "\n",
    "def build_parent_workflow(storage: FileCheckpointStorage) -> tuple[LaunchCoordinator, Workflow]:\n",
    "    coordinator = LaunchCoordinator()\n",
    "    sub_executor = build_sub_workflow()\n",
    "    parent_request_info = RequestInfoExecutor(id=\"parent_review_gateway\")\n",
    "\n",
    "    workflow = (\n",
    "        WorkflowBuilder()\n",
    "        .set_start_executor(coordinator)\n",
    "        .add_edge(coordinator, sub_executor)\n",
    "        .add_edge(sub_executor, coordinator, condition=lambda msg: isinstance(msg, FinalDraft))\n",
    "        .add_edge(\n",
    "            sub_executor,\n",
    "            parent_request_info,\n",
    "            condition=lambda msg: isinstance(msg, RequestInfoMessage),\n",
    "        )\n",
    "        .add_edge(parent_request_info, sub_executor)\n",
    "        .with_checkpointing(storage)\n",
    "        .build()\n",
    "    )\n",
    "\n",
    "    return coordinator, workflow\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Run the staged demo\n",
    "The `main` coroutine runs until a human review is needed, shows the saved checkpoint, and then resumes with an auto-approved response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main() -> None:\n",
    "    CHECKPOINT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    for file in CHECKPOINT_DIR.glob(\"*.json\"):\n",
    "        file.unlink()\n",
    "\n",
    "    storage = FileCheckpointStorage(CHECKPOINT_DIR)\n",
    "\n",
    "    _, workflow = build_parent_workflow(storage)\n",
    "\n",
    "    print(\"\\n=== Stage 1: run until sub-workflow requests human review ===\")\n",
    "    request_id: str | None = None\n",
    "    async for event in workflow.run_stream(\"Contoso Gadget Launch\"):\n",
    "        if isinstance(event, RequestInfoEvent) and request_id is None:\n",
    "            request_id = event.request_id\n",
    "            print(f\"Captured review request id: {request_id}\")\n",
    "        if isinstance(event, WorkflowStatusEvent) and event.state is WorkflowRunState.IDLE_WITH_PENDING_REQUESTS:\n",
    "            break\n",
    "\n",
    "    if request_id is None:\n",
    "        print(\"Sub-workflow completed without requesting review.\")\n",
    "        return\n",
    "\n",
    "    checkpoints = await storage.list_checkpoints(workflow.id)\n",
    "    if not checkpoints:\n",
    "        print(\"No checkpoints written.\")\n",
    "        return\n",
    "\n",
    "    checkpoints.sort(key=lambda cp: cp.timestamp)\n",
    "    resume_checkpoint = checkpoints[-1]\n",
    "    print(f\"Using checkpoint {resume_checkpoint.checkpoint_id} at iteration {resume_checkpoint.iteration_count}\")\n",
    "\n",
    "    checkpoint_path = storage.storage_path / f\"{resume_checkpoint.checkpoint_id}.json\"\n",
    "    if checkpoint_path.exists():\n",
    "        snapshot = json.loads(checkpoint_path.read_text())\n",
    "        exec_states = snapshot.get(\"executor_states\", {})\n",
    "        sub_pending = exec_states.get(\"sub_review_requests\", {}).get(\"request_events\", {})\n",
    "        parent_pending = exec_states.get(\"parent_review_gateway\", {}).get(\"request_events\", {})\n",
    "        print(f\"Pending review requests (sub executor snapshot): {list(sub_pending.keys())}\")\n",
    "        print(f\"Pending review requests (parent executor snapshot): {list(parent_pending.keys())}\")\n",
    "\n",
    "    print(\"\\n=== Stage 2: resume from checkpoint and approve draft ===\")\n",
    "    # Rebuild fresh instances to mimic a separate process resuming\n",
    "    coordinator2, workflow2 = build_parent_workflow(storage)\n",
    "\n",
    "    approval_response = \"approve\"\n",
    "    final_event: WorkflowOutputEvent | None = None\n",
    "    async for event in workflow2.run_stream_from_checkpoint(\n",
    "        resume_checkpoint.checkpoint_id,\n",
    "        responses={request_id: approval_response},\n",
    "    ):\n",
    "        if isinstance(event, WorkflowOutputEvent):\n",
    "            final_event = event\n",
    "\n",
    "    if final_event is None:\n",
    "        print(\"Workflow did not complete after resume.\")\n",
    "        return\n",
    "\n",
    "    final = final_event.data\n",
    "    print(\"\\n=== Final Draft (from resumed run) ===\")\n",
    "    print(final)\n",
    "\n",
    "    if coordinator2.final_result is None:\n",
    "        print(\"Coordinator did not capture final result via handler.\")\n",
    "    else:\n",
    "        print(\"Coordinator stored final draft successfully.\")\n",
    "\n",
    "    \"\"\"\"\n",
    "    Sample Output:\n",
    "\n",
    "    === Stage 1: run until sub-workflow requests human review ===\n",
    "    Captured review request id: 032c9f3a-ad1b-4a52-89be-a168d6663011\n",
    "    Using checkpoint 54f376c2-f849-44e4-9d8d-e627fd27ab96 at iteration 2\n",
    "    Pending review requests (sub executor snapshot): []\n",
    "    Pending review requests (parent executor snapshot): ['032c9f3a-ad1b-4a52-89be-a168d6663011']\n",
    "\n",
    "    === Stage 2: resume from checkpoint and approve draft ===\n",
    "\n",
    "    >>> Parent workflow received approved draft:\n",
    "    - Topic: Contoso Gadget Launch\n",
    "    - Iterations: 1\n",
    "    - Approved at: 2025-09-25T14:29:34.479164\n",
    "    - Content: Approved launch narrative for Contoso Gadget Launch (iteration 1).\n",
    "\n",
    "\n",
    "    === Final Draft (from resumed run) ===\n",
    "    FinalDraft(topic='Contoso Gadget Launch', content='Approved launch narrative for Contoso\n",
    "    Gadget Launch (iteration 1).', iterations=1, approved_at=datetime.datetime(2025, 9, 25, 14, 29, 34, 479164))\n",
    "    Coordinator stored final draft successfully.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step ??: Try it yourself\n",
    "Use the helper below. In notebooks it awaits `main()` on the active loop; in scripts it falls back to `asyncio.run(main())`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "# Helper for notebooks vs. scripts\n",
    "loop = asyncio.get_event_loop()\n",
    "if loop.is_running():\n",
    "    # Jupyter/VS Code notebooks already have an event loop, so await directly.\n",
    "    await main()\n",
    "else:\n",
    "    asyncio.run(main())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
