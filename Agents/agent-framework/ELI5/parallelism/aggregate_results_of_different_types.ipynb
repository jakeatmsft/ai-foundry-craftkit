{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# aggregate_results_of_different_types.py - ELI5 Walkthrough\n",
    "This notebook recreates `python/samples/getting_started/workflows/parallelism/aggregate_results_of_different_types.py` so you can follow the fan-out/fan-in pattern step by step.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big Picture\n",
    "A dispatcher fans out a list of numbers to two workers (Average and Sum). Their outputs are fanned back in by an Aggregator that collects multiple result types in a single list.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Ingredients\n",
    "- `WorkflowBuilder.add_fan_out_edges` and `.add_fan_in_edges` express parallel branches and joins.\n",
    "- Executors send messages with typed `WorkflowContext`.\n",
    "- Streaming run emits `WorkflowOutputEvent` when the fan-in node yields results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow Diagram\n",
    "```mermaid\n",
    "flowchart LR\n",
    "    Start([\"Number List\"]) --> Dispatcher[[Dispatcher]]\n",
    "    Dispatcher --> Average[[Average]]\n",
    "    Dispatcher --> Sum[[Sum]]\n",
    "    Average --> Aggregator[[Aggregator]]\n",
    "    Sum --> Aggregator\n",
    "    Aggregator --> Output([\"[sum, average]\"])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Imports and scenario overview\n",
    "We load the Agent Framework primitives, configure environment variables, and keep the docstring describing the fan-out/fan-in demo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSample: Concurrent fan out and fan in with two different tasks that output results of different types.\\n\\nPurpose:\\nShow how to construct a parallel branch pattern in workflows. Demonstrate:\\n- Fan out by targeting multiple executors from one dispatcher.\\n- Fan in by collecting a list of results from the executors.\\n- Simple tracing using AgentRunEvent to observe execution order and progress.\\n\\nPrerequisites:\\n- Familiarity with WorkflowBuilder, executors, edges, events, and streaming runs.\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copyright (c) Microsoft. All rights reserved.\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import asyncio\n",
    "import random\n",
    "\n",
    "from agent_framework import Executor, WorkflowBuilder, WorkflowContext, WorkflowOutputEvent, handler\n",
    "from typing_extensions import Never\n",
    "\n",
    "\"\"\"\n",
    "Sample: Concurrent fan out and fan in with two different tasks that output results of different types.\n",
    "\n",
    "Purpose:\n",
    "Show how to construct a parallel branch pattern in workflows. Demonstrate:\n",
    "- Fan out by targeting multiple executors from one dispatcher.\n",
    "- Fan in by collecting a list of results from the executors.\n",
    "- Simple tracing using AgentRunEvent to observe execution order and progress.\n",
    "\n",
    "Prerequisites:\n",
    "- Familiarity with WorkflowBuilder, executors, edges, events, and streaming runs.\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Dispatcher fans out the input\n",
    "`Dispatcher` validates the incoming list and forwards it to each parallel worker.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dispatcher(Executor):\n",
    "    \"\"\"\n",
    "    The sole purpose of this decorator is to dispatch the input of the workflow to\n",
    "    other executors.\n",
    "    \"\"\"\n",
    "\n",
    "    @handler\n",
    "    async def handle(self, numbers: list[int], ctx: WorkflowContext[list[int]]):\n",
    "        print(f\"📤 Dispatcher [{self.id}]: Received {len(numbers)} numbers: {numbers}\")\n",
    "        print(f\"📤 Dispatcher [{self.id}]: Input range: min={min(numbers)}, max={max(numbers)}\")\n",
    "        \n",
    "        if not numbers:\n",
    "            raise RuntimeError(\"Input must be a valid list of integers.\")\n",
    "\n",
    "        print(f\"📤 Dispatcher [{self.id}]: Sending numbers to parallel workers...\")\n",
    "        await ctx.send_message(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Worker executors compute their metrics\n",
    "`Average` and `Sum` each take the same list and emit their numeric result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Average(Executor):\n",
    "    \"\"\"Calculate the average of a list of integers.\"\"\"\n",
    "\n",
    "    @handler\n",
    "    async def handle(self, numbers: list[int], ctx: WorkflowContext[float]):\n",
    "        print(f\"🧮 Average [{self.id}]: Processing {len(numbers)} numbers...\")\n",
    "        print(f\"🧮 Average [{self.id}]: Input sum: {sum(numbers)}, count: {len(numbers)}\")\n",
    "        average: float = sum(numbers) / len(numbers)\n",
    "        print(f\"🧮 Average [{self.id}]: Calculated average = {average:.2f} (formula: {sum(numbers)}/{len(numbers)})\")\n",
    "        await ctx.send_message(average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sum(Executor):\n",
    "    \"\"\"Calculate the sum of a list of integers.\"\"\"\n",
    "\n",
    "    @handler\n",
    "    async def handle(self, numbers: list[int], ctx: WorkflowContext[int]):\n",
    "        print(f\"➕ Sum [{self.id}]: Processing {len(numbers)} numbers...\")\n",
    "        print(f\"➕ Sum [{self.id}]: Input values: {numbers}\")\n",
    "        total: int = sum(numbers)\n",
    "        print(f\"➕ Sum [{self.id}]: Calculated sum = {total} (type: {type(total).__name__})\")\n",
    "        await ctx.send_message(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Aggregator fans the results back in\n",
    "`Aggregator` receives a heterogeneous list (`int | float`) and yields it as the final workflow output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Aggregator(Executor):\n",
    "    \"\"\"Aggregate the results from the different tasks and yield the final output.\"\"\"\n",
    "\n",
    "    @handler\n",
    "    async def handle(self, results: list[int | float], ctx: WorkflowContext[Never, list[int | float]]):\n",
    "        \"\"\"Receive the results from the source executors.\n",
    "\n",
    "        The framework will automatically collect messages from the source executors\n",
    "        and deliver them as a list.\n",
    "\n",
    "        Args:\n",
    "            results (list[int | float]): execution results from upstream executors.\n",
    "                The type annotation must be a list of union types that the upstream\n",
    "                executors will produce.\n",
    "            ctx (WorkflowContext[Never, list[int | float]]): A workflow context that can yield the final output.\n",
    "        \"\"\"\n",
    "        print(f\"📊 Aggregator [{self.id}]: Received {len(results)} results from upstream workers\")\n",
    "        print(f\"📊 Aggregator [{self.id}]: Result types: {[type(r).__name__ for r in results]}\")\n",
    "        print(f\"📊 Aggregator [{self.id}]: Result values: {results}\")\n",
    "        print(f\"📊 Aggregator [{self.id}]: Yielding final output (type: {type(results).__name__})...\")\n",
    "        await ctx.yield_output(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Wire and run the workflow\n",
    "`main()` constructs the graph, executes it with random numbers, and prints the collected outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main() -> None:\n",
    "    # 1) Create the executors\n",
    "    print(\"🏗️  Creating executors...\")\n",
    "    dispatcher = Dispatcher(id=\"dispatcher\")\n",
    "    average = Average(id=\"average\")\n",
    "    summation = Sum(id=\"summation\")\n",
    "    aggregator = Aggregator(id=\"aggregator\")\n",
    "    \n",
    "    executor_names = [dispatcher.id, average.id, summation.id, aggregator.id]\n",
    "    print(f\"✅ Executors created: {', '.join(executor_names)} (total: {len(executor_names)})\")\n",
    "\n",
    "    # 2) Build a simple fan out and fan in workflow\n",
    "    print(f\"\\n🔧 Building workflow...\")\n",
    "    workflow = (\n",
    "        WorkflowBuilder()\n",
    "        .set_start_executor(dispatcher)\n",
    "        .add_fan_out_edges(dispatcher, [average, summation])\n",
    "        .add_fan_in_edges([average, summation], aggregator)\n",
    "        .build()\n",
    "    )\n",
    "    print(f\"✅ Workflow built with fan-out/fan-in pattern\")\n",
    "    print(f\"   - Start: {dispatcher.id}\")\n",
    "    print(f\"   - Fan-out targets: {[average.id, summation.id]}\")\n",
    "    print(f\"   - Fan-in source: [{average.id}, {summation.id}] -> {aggregator.id}\")\n",
    "\n",
    "    # 3) Run the workflow\n",
    "    print(f\"\\n🎲 Generating random input data...\")\n",
    "    input_numbers = [random.randint(1, 100) for _ in range(16)]\n",
    "    print(f\"📊 Input numbers ({len(input_numbers)} values): {input_numbers}\")\n",
    "    print(f\"📊 Input statistics: min={min(input_numbers)}, max={max(input_numbers)}, sum={sum(input_numbers)}\")\n",
    "    \n",
    "    print(f\"\\n🚀 Running workflow...\")\n",
    "    output: list[int | float] | None = None\n",
    "    event_count = 0\n",
    "    \n",
    "    async for event in workflow.run_stream(input_numbers):\n",
    "        event_count += 1\n",
    "        event_type = type(event).__name__\n",
    "        print(f\"⚡ Event {event_count}: {event_type}\")\n",
    "        \n",
    "        if isinstance(event, WorkflowOutputEvent):\n",
    "            output = event.data\n",
    "            print(f\"🎯 Workflow completed! Output received: {output} (type: {type(output).__name__})\")\n",
    "\n",
    "    if output is not None:\n",
    "        print(f\"\\n🏆 Final Result: {output}\")\n",
    "        print(f\"   - Sum: {output[0]} (type: {type(output[0]).__name__})\")\n",
    "        print(f\"   - Average: {output[1]} (type: {type(output[1]).__name__})\")\n",
    "        print(f\"   - Total events processed: {event_count}\")\n",
    "    else:\n",
    "        print(\"❌ No output received from workflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Try it yourself\n",
    "Use the helper below. In notebooks it awaits `main()` on the active loop; in scripts it falls back to `asyncio.run(main())`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏗️  Creating executors...\n",
      "✅ Executors created: dispatcher, average, summation, aggregator (total: 4)\n",
      "\n",
      "🔧 Building workflow...\n",
      "✅ Workflow built with fan-out/fan-in pattern\n",
      "   - Start: dispatcher\n",
      "   - Fan-out targets: ['average', 'summation']\n",
      "   - Fan-in source: [average, summation] -> aggregator\n",
      "\n",
      "🎲 Generating random input data...\n",
      "📊 Input numbers (16 values): [7, 36, 46, 49, 33, 58, 1, 7, 11, 18, 81, 51, 23, 2, 9, 52]\n",
      "📊 Input statistics: min=1, max=81, sum=484\n",
      "\n",
      "🚀 Running workflow...\n",
      "⚡ Event 1: WorkflowStartedEvent\n",
      "⚡ Event 2: WorkflowStatusEvent\n",
      "📤 Dispatcher [dispatcher]: Received 16 numbers: [7, 36, 46, 49, 33, 58, 1, 7, 11, 18, 81, 51, 23, 2, 9, 52]\n",
      "📤 Dispatcher [dispatcher]: Input range: min=1, max=81\n",
      "📤 Dispatcher [dispatcher]: Sending numbers to parallel workers...\n",
      "⚡ Event 3: ExecutorInvokedEvent\n",
      "⚡ Event 4: ExecutorCompletedEvent\n",
      "🧮 Average [average]: Processing 16 numbers...\n",
      "🧮 Average [average]: Input sum: 484, count: 16\n",
      "🧮 Average [average]: Calculated average = 30.25 (formula: 484/16)\n",
      "➕ Sum [summation]: Processing 16 numbers...\n",
      "➕ Sum [summation]: Input values: [7, 36, 46, 49, 33, 58, 1, 7, 11, 18, 81, 51, 23, 2, 9, 52]\n",
      "➕ Sum [summation]: Calculated sum = 484 (type: int)\n",
      "⚡ Event 5: ExecutorInvokedEvent\n",
      "⚡ Event 6: ExecutorCompletedEvent\n",
      "⚡ Event 7: ExecutorInvokedEvent\n",
      "⚡ Event 8: ExecutorCompletedEvent\n",
      "📊 Aggregator [aggregator]: Received 2 results from upstream workers\n",
      "📊 Aggregator [aggregator]: Result types: ['float', 'int']\n",
      "📊 Aggregator [aggregator]: Result values: [30.25, 484]\n",
      "📊 Aggregator [aggregator]: Yielding final output (type: list)...\n",
      "⚡ Event 9: ExecutorInvokedEvent\n",
      "⚡ Event 10: WorkflowOutputEvent\n",
      "🎯 Workflow completed! Output received: [30.25, 484] (type: list)\n",
      "⚡ Event 11: ExecutorCompletedEvent\n",
      "⚡ Event 12: WorkflowStatusEvent\n",
      "\n",
      "🏆 Final Result: [30.25, 484]\n",
      "   - Sum: 30.25 (type: float)\n",
      "   - Average: 484 (type: int)\n",
      "   - Total events processed: 12\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "# Helper for notebooks vs. scripts\n",
    "loop = asyncio.get_event_loop()\n",
    "if loop.is_running():\n",
    "    # Jupyter/VS Code notebooks already have an event loop, so await directly.\n",
    "    await main()\n",
    "else:\n",
    "    asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a85f7ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
