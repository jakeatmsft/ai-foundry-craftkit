{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fan_out_fan_in_edges.py - ELI5 Walkthrough\n",
    "This notebook walks through `python/samples/getting_started/workflows/parallelism/fan_out_fan_in_edges.py` with diagrams and commentary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big Picture\n",
    "One dispatcher fans out a marketing brief to researcher, marketer, and legal agents. Their responses are fanned back in and aggregated into a single report.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Ingredients\n",
    "- Agent executors created by `AzureOpenAIChatClient`.\n",
    "- Fan-out edges from the dispatcher to multiple experts.\n",
    "- Fan-in edges into an aggregator that merges structured agent responses.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow Diagram\n",
    "```mermaid\n",
    "flowchart LR\n",
    "    Start([\"Launch Prompt\"]) --> Dispatcher[[DispatchToExperts]]\n",
    "    Dispatcher --> Researcher[[researcher AgentExecutor]]\n",
    "    Dispatcher --> Marketer[[marketer AgentExecutor]]\n",
    "    Dispatcher --> Legal[[legal AgentExecutor]]\n",
    "    Researcher --> Aggregator[[AggregateInsights]]\n",
    "    Marketer --> Aggregator\n",
    "    Legal --> Aggregator\n",
    "    Aggregator --> Output([\"Consolidated Insights\"])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Imports and scenario description\n",
    "We import Agent Framework classes, configure Azure authentication, and keep the docstring explaining the parallel expert pattern.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Microsoft. All rights reserved.\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import asyncio\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from agent_framework import (  # Core chat primitives to build LLM requests\n",
    "    AgentExecutor,  # Wraps an LLM agent for use inside a workflow\n",
    "    AgentExecutorRequest,  # The message bundle sent to an AgentExecutor\n",
    "    AgentExecutorResponse,  # The structured result returned by an AgentExecutor\n",
    "    AgentRunEvent,  # Tracing event for agent execution steps\n",
    "    ChatMessage,  # Chat message structure\n",
    "    Executor,  # Base class for custom Python executors\n",
    "    Role,  # Enum of chat roles (user, assistant, system)\n",
    "    WorkflowBuilder,  # Fluent builder for wiring the workflow graph\n",
    "    WorkflowContext,  # Per run context and event bus\n",
    "    WorkflowOutputEvent,  # Event emitted when workflow yields output\n",
    "    handler,  # Decorator to mark an Executor method as invokable\n",
    ")\n",
    "from agent_framework.azure import AzureOpenAIChatClient  # Client wrapper for Azure OpenAI chat models\n",
    "from azure.identity import AzureCliCredential  # Uses your az CLI login for credentials\n",
    "from typing_extensions import Never\n",
    "\n",
    "\"\"\"\n",
    "Sample: Concurrent fan out and fan in with three domain agents\n",
    "\n",
    "A dispatcher fans out the same user prompt to research, marketing, and legal AgentExecutor nodes.\n",
    "An aggregator then fans in their responses and produces a single consolidated report.\n",
    "\n",
    "Purpose:\n",
    "Show how to construct a parallel branch pattern in workflows. Demonstrate:\n",
    "- Fan out by targeting multiple AgentExecutor nodes from one dispatcher.\n",
    "- Fan in by collecting a list of AgentExecutorResponse objects and reducing them to a single result.\n",
    "- Simple tracing using AgentRunEvent to observe execution order and progress.\n",
    "\n",
    "Prerequisites:\n",
    "- Familiarity with WorkflowBuilder, executors, edges, events, and streaming runs.\n",
    "- Azure OpenAI access configured for AzureOpenAIChatClient. Log in with Azure CLI and set any required environment variables.\n",
    "- Comfort reading AgentExecutorResponse.agent_run_response.text for assistant output aggregation.\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Dispatcher fans out to expert agents\n",
    "`DispatchToExperts` clones the user prompt and sends it to each expert `AgentExecutor`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DispatchToExperts(Executor):\n",
    "    \"\"\"Dispatches the incoming prompt to all expert agent executors for parallel processing (fan out).\"\"\"\n",
    "\n",
    "    def __init__(self, expert_ids: list[str], id: str | None = None):\n",
    "        super().__init__(id=id or \"dispatch_to_experts\")\n",
    "        self._expert_ids = expert_ids\n",
    "\n",
    "    @handler\n",
    "    async def dispatch(self, prompt: str, ctx: WorkflowContext[AgentExecutorRequest]) -> None:\n",
    "        # Wrap the incoming prompt as a user message for each expert and request a response.\n",
    "        # Each send_message targets a different AgentExecutor by id so that branches run in parallel.\n",
    "        initial_message = ChatMessage(Role.USER, text=prompt)\n",
    "        for expert_id in self._expert_ids:\n",
    "            await ctx.send_message(\n",
    "                AgentExecutorRequest(messages=[initial_message], should_respond=True),\n",
    "                target_id=expert_id,\n",
    "            )\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class AggregatedInsights:\n",
    "    \"\"\"Typed container for the aggregator to hold per domain strings before formatting.\"\"\"\n",
    "\n",
    "    research: str\n",
    "    marketing: str\n",
    "    legal: str\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Aggregator fans responses back in\n",
    "`AggregateInsights` turns the list of `AgentExecutorResponse` objects into a consolidated report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AggregateInsights(Executor):\n",
    "    \"\"\"Aggregates expert agent responses into a single consolidated result (fan in).\"\"\"\n",
    "\n",
    "    def __init__(self, expert_ids: list[str], id: str | None = None):\n",
    "        super().__init__(id=id or \"aggregate_insights\")\n",
    "        self._expert_ids = expert_ids\n",
    "\n",
    "    @handler\n",
    "    async def aggregate(self, results: list[AgentExecutorResponse], ctx: WorkflowContext[Never, str]) -> None:\n",
    "        # Map responses to text by executor id for a simple, predictable demo.\n",
    "        by_id: dict[str, str] = {}\n",
    "        for r in results:\n",
    "            # AgentExecutorResponse.agent_run_response.text is the assistant text produced by the agent.\n",
    "            by_id[r.executor_id] = r.agent_run_response.text\n",
    "\n",
    "        research_text = by_id.get(\"researcher\", \"\")\n",
    "        marketing_text = by_id.get(\"marketer\", \"\")\n",
    "        legal_text = by_id.get(\"legal\", \"\")\n",
    "\n",
    "        aggregated = AggregatedInsights(\n",
    "            research=research_text,\n",
    "            marketing=marketing_text,\n",
    "            legal=legal_text,\n",
    "        )\n",
    "\n",
    "        # Provide a readable, consolidated string as the final workflow result.\n",
    "        consolidated = (\n",
    "            \"Consolidated Insights\\n\"\n",
    "            \"====================\\n\\n\"\n",
    "            f\"Research Findings:\\n{aggregated.research}\\n\\n\"\n",
    "            f\"Marketing Angle:\\n{aggregated.marketing}\\n\\n\"\n",
    "            f\"Legal/Compliance Notes:\\n{aggregated.legal}\\n\"\n",
    "        )\n",
    "\n",
    "        await ctx.yield_output(consolidated)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Build and stream the workflow\n",
    "`main()` configures each expert agent, wires the graph, and streams events so you can watch agent execution before the final output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main() -> None:\n",
    "    # 1) Create agent executors for domain experts\n",
    "    chat_client = AzureOpenAIChatClient(credential=AzureCliCredential())\n",
    "\n",
    "    researcher = AgentExecutor(\n",
    "        chat_client.create_agent(\n",
    "            instructions=(\n",
    "                \"You're an expert market and product researcher. Given a prompt, provide concise, factual insights,\"\n",
    "                \" opportunities, and risks.\"\n",
    "            ),\n",
    "        ),\n",
    "        id=\"researcher\",\n",
    "    )\n",
    "    marketer = AgentExecutor(\n",
    "        chat_client.create_agent(\n",
    "            instructions=(\n",
    "                \"You're a creative marketing strategist. Craft compelling value propositions and target messaging\"\n",
    "                \" aligned to the prompt.\"\n",
    "            ),\n",
    "        ),\n",
    "        id=\"marketer\",\n",
    "    )\n",
    "    legal = AgentExecutor(\n",
    "        chat_client.create_agent(\n",
    "            instructions=(\n",
    "                \"You're a cautious legal/compliance reviewer. Highlight constraints, disclaimers, and policy concerns\"\n",
    "                \" based on the prompt.\"\n",
    "            ),\n",
    "        ),\n",
    "        id=\"legal\",\n",
    "    )\n",
    "\n",
    "    expert_ids = [researcher.id, marketer.id, legal.id]\n",
    "\n",
    "    dispatcher = DispatchToExperts(expert_ids=expert_ids, id=\"dispatcher\")\n",
    "    aggregator = AggregateInsights(expert_ids=expert_ids, id=\"aggregator\")\n",
    "\n",
    "    # 2) Build a simple fan out and fan in workflow\n",
    "    workflow = (\n",
    "        WorkflowBuilder()\n",
    "        .set_start_executor(dispatcher)\n",
    "        .add_fan_out_edges(dispatcher, [researcher, marketer, legal])  # Parallel branches\n",
    "        .add_fan_in_edges([researcher, marketer, legal], aggregator)  # Join at the aggregator\n",
    "        .build()\n",
    "    )\n",
    "\n",
    "    # 3) Run with a single prompt and print progress plus the final consolidated output\n",
    "    async for event in workflow.run_stream(\"We are launching a new budget-friendly electric bike for urban commuters.\"):\n",
    "        if isinstance(event, AgentRunEvent):\n",
    "            # Show which agent ran and what step completed for lightweight observability.\n",
    "            print(event)\n",
    "        elif isinstance(event, WorkflowOutputEvent):\n",
    "            print(\"===== Final Aggregated Output =====\")\n",
    "            print(event.data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Try it yourself\n",
    "Use the helper below. In notebooks it awaits `main()` on the active loop; in scripts it falls back to `asyncio.run(main())`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "# Helper for notebooks vs. scripts\n",
    "loop = asyncio.get_event_loop()\n",
    "if loop.is_running():\n",
    "    # Jupyter/VS Code notebooks already have an event loop, so await directly.\n",
    "    await main()\n",
    "else:\n",
    "    asyncio.run(main())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
