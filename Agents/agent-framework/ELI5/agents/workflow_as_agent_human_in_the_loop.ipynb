{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# workflow_as_agent_human_in_the_loop.py - ELI5 Walkthrough\n",
    "This notebook rebuilds `python/samples/getting_started/workflows/agents/workflow_as_agent_human_in_the_loop.py` in-place so you can explore it piece by piece.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big Picture\n",
    "A workflow agent handles most reviews automatically. When the Reviewer executor lacks confidence, it emits a human review request. Your app receives a structured function call, collects the manager's decision, and feeds it back so the Worker can continue.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Ingredients\n",
    "- `WorkflowAgent` wraps a workflow so you can call it like any other chat agent.\n",
    "- A `Worker` executor drafts answers, and a reviewer decides whether to escalate.\n\n",
    "- `RequestInfoExecutor` pauses the workflow and surfaces a structured function call for the human.\n",
    "- The driver code inspects messages for `WorkflowAgent.REQUEST_INFO_FUNCTION_NAME` and replies with a `FunctionResultContent`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow Diagram\n",
    "```mermaid\n",
    "flowchart LR\n",
    "    Start([\"User Query\"]) --> Worker[[Worker Executor]]\n",
    "    Worker --> Reviewer[[Reviewer Executor]]\n",
    "    Reviewer --> RequestInfo[/RequestInfoExecutor/]\n",
    "    RequestInfo --> Human[\"Human Manager\"]\n",
    "    Human --> Reviewer\n",
    "    Reviewer --> Worker\n",
    "    Worker --> Output([\"Agent Response Stream\"])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load dependencies and describe the scenario\n",
    "We import the Agent Framework pieces, set up environment variables, and hold a short docstring summarising the workflow's goal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Microsoft. All rights reserved.\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import asyncio\n",
    "from collections.abc import Mapping\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, cast\n",
    "from uuid import uuid4\n",
    "\n",
    "from agent_framework import (\n",
    "    AgentRunResponseUpdate,\n",
    "    AgentRunUpdateEvent,\n",
    "    ChatClientProtocol,\n",
    "    ChatMessage,\n",
    "    Contents,\n",
    "    Executor,\n",
    "    FunctionCallContent,\n",
    "    FunctionResultContent,\n",
    "    RequestInfoExecutor,\n",
    "    RequestInfoMessage,\n",
    "    RequestResponse,\n",
    "    Role,\n",
    "    WorkflowAgent,\n",
    "    WorkflowBuilder,\n",
    "    WorkflowContext,\n",
    "    handler,\n",
    ")\n",
    "from agent_framework.openai import OpenAIChatClient\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\"\"\"\n",
    "Sample: Workflow Agent with Human-in-the-Loop\n",
    "\n",
    "This walkthrough shows how to wrap a workflow as an agent and escalate tricky\n",
    "cases to a human. A worker executor proposes answers, a reviewer escalates the\n",
    "uncertain ones, and the workflow agent surfaces a structured function call so\n",
    "your application can gather the human decision.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Reuse the reflection pattern building blocks\n",
    "We embed the `ReviewRequest`, `ReviewResponse`, and `Worker` classes from the reflection pattern sample. The Worker tracks pending requests, emits approved answers, and retries when feedback says \"try again\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ReviewRequest:\n",
    "    \"\"\"Structured request passed from Worker to Reviewer for evaluation.\"\"\"\n",
    "\n",
    "    request_id: str\n",
    "    user_messages: list[ChatMessage]\n",
    "    agent_messages: list[ChatMessage]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ReviewResponse:\n",
    "    \"\"\"Structured response from Reviewer back to Worker.\"\"\"\n",
    "\n",
    "    request_id: str\n",
    "    feedback: str\n",
    "    approved: bool\n",
    "\n",
    "\n",
    "class Reviewer(Executor):\n",
    "    \"\"\"Executor that reviews agent responses and provides structured feedback.\"\"\"\n",
    "\n",
    "    def __init__(self, id: str, chat_client: ChatClientProtocol) -> None:\n",
    "        super().__init__(id=id)\n",
    "        self._chat_client = chat_client\n",
    "\n",
    "    @handler\n",
    "    async def review(self, request: ReviewRequest, ctx: WorkflowContext[ReviewResponse]) -> None:\n",
    "        print(f\"Reviewer: Evaluating response for request {request.request_id[:8]}...\")\n",
    "\n",
    "        # Define structured schema for the LLM to return.\n",
    "        class _Response(BaseModel):\n",
    "            feedback: str\n",
    "            approved: bool\n",
    "\n",
    "        # Construct review instructions and context.\n",
    "        messages = [\n",
    "            ChatMessage(\n",
    "                role=Role.SYSTEM,\n",
    "                text=(\n",
    "                    \"You are a reviewer for an AI agent. Provide feedback on the \"\n",
    "                    \"exchange between a user and the agent. Indicate approval only if:\\n\"\n",
    "                    \"- Relevance: response addresses the query\\n\"\n",
    "                    \"- Accuracy: information is correct\\n\"\n",
    "                    \"- Clarity: response is easy to understand\\n\"\n",
    "                    \"- Completeness: response covers all aspects\\n\"\n",
    "                    \"Do not approve until all criteria are satisfied.\"\n",
    "                ),\n",
    "            )\n",
    "        ]\n",
    "        # Add conversation history.\n",
    "        messages.extend(request.user_messages)\n",
    "        messages.extend(request.agent_messages)\n",
    "\n",
    "        # Add explicit review instruction.\n",
    "        messages.append(ChatMessage(role=Role.USER, text=\"Please review the agent's responses.\"))\n",
    "\n",
    "        print(\"Reviewer: Sending review request to LLM...\")\n",
    "        response = await self._chat_client.get_response(messages=messages, response_format=_Response)\n",
    "\n",
    "        parsed = _Response.model_validate_json(response.messages[-1].text)\n",
    "\n",
    "        print(f\"Reviewer: Review complete - Approved: {parsed.approved}\")\n",
    "        print(f\"Reviewer: Feedback: {parsed.feedback}\")\n",
    "\n",
    "        # Send structured review result to Worker.\n",
    "        await ctx.send_message(\n",
    "            ReviewResponse(request_id=request.request_id, feedback=parsed.feedback, approved=parsed.approved)\n",
    "        )\n",
    "\n",
    "\n",
    "class Worker(Executor):\n",
    "    \"\"\"Executor that generates responses and incorporates feedback when necessary.\"\"\"\n",
    "\n",
    "    def __init__(self, id: str, chat_client: ChatClientProtocol) -> None:\n",
    "        super().__init__(id=id)\n",
    "        self._chat_client = chat_client\n",
    "        self._pending_requests: dict[str, tuple[ReviewRequest, list[ChatMessage]]] = {}\n",
    "\n",
    "    @handler\n",
    "    async def handle_user_messages(self, user_messages: list[ChatMessage], ctx: WorkflowContext[ReviewRequest]) -> None:\n",
    "        print(\"Worker: Received user messages, generating response...\")\n",
    "\n",
    "        # Initialize chat with system prompt.\n",
    "        messages = [ChatMessage(role=Role.SYSTEM, text=\"You are a helpful assistant.\")]\n",
    "        messages.extend(user_messages)\n",
    "\n",
    "        print(\"Worker: Calling LLM to generate response...\")\n",
    "        response = await self._chat_client.get_response(messages=messages)\n",
    "        print(f\"Worker: Response generated: {response.messages[-1].text}\")\n",
    "\n",
    "        # Add agent messages to context.\n",
    "        messages.extend(response.messages)\n",
    "\n",
    "        # Create review request and send to Reviewer.\n",
    "        request = ReviewRequest(request_id=str(uuid4()), user_messages=user_messages, agent_messages=response.messages)\n",
    "        print(f\"Worker: Sending response for review (ID: {request.request_id[:8]})\")\n",
    "        await ctx.send_message(request)\n",
    "\n",
    "        # Track request for possible retry.\n",
    "        self._pending_requests[request.request_id] = (request, messages)\n",
    "\n",
    "    @handler\n",
    "    async def handle_review_response(self, review: ReviewResponse, ctx: WorkflowContext[ReviewRequest]) -> None:\n",
    "        print(f\"Worker: Received review for request {review.request_id[:8]} - Approved: {review.approved}\")\n",
    "\n",
    "        if review.request_id not in self._pending_requests:\n",
    "            raise ValueError(f\"Unknown request ID in review: {review.request_id}\")\n",
    "\n",
    "        request, messages = self._pending_requests.pop(review.request_id)\n",
    "\n",
    "        if review.approved:\n",
    "            print(\"Worker: Response approved. Emitting to external consumer...\")\n",
    "            contents: list[Contents] = []\n",
    "            for message in request.agent_messages:\n",
    "                contents.extend(message.contents)\n",
    "\n",
    "            # Emit approved result to external consumer via AgentRunUpdateEvent.\n",
    "            await ctx.add_event(\n",
    "                AgentRunUpdateEvent(self.id, data=AgentRunResponseUpdate(contents=contents, role=Role.ASSISTANT))\n",
    "            )\n",
    "            return\n",
    "\n",
    "        print(f\"Worker: Response not approved. Feedback: {review.feedback}\")\n",
    "        print(\"Worker: Regenerating response with feedback...\")\n",
    "\n",
    "        # Incorporate review feedback.\n",
    "        messages.append(ChatMessage(role=Role.SYSTEM, text=review.feedback))\n",
    "        messages.append(\n",
    "            ChatMessage(role=Role.SYSTEM, text=\"Please incorporate the feedback and regenerate the response.\")\n",
    "        )\n",
    "        messages.extend(request.user_messages)\n",
    "\n",
    "        # Retry with updated prompt.\n",
    "        response = await self._chat_client.get_response(messages=messages)\n",
    "        print(f\"Worker: New response generated: {response.messages[-1].text}\")\n",
    "\n",
    "        messages.extend(response.messages)\n",
    "\n",
    "        # Send updated request for re-review.\n",
    "        new_request = ReviewRequest(\n",
    "            request_id=review.request_id, user_messages=request.user_messages, agent_messages=response.messages\n",
    "        )\n",
    "        await ctx.send_message(new_request)\n",
    "\n",
    "        # Track new request for further evaluation.\n",
    "        self._pending_requests[new_request.request_id] = (new_request, messages)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Escalate reviews to a human manager\n",
    "`ReviewerWithHumanInTheLoop` sends every review to a `RequestInfoExecutor`, waits for the human's `ReviewResponse`, and forwards it back to the Worker.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class HumanReviewRequest(RequestInfoMessage):\n",
    "    \"\"\"Payload escalated to a human reviewer.\"\"\"\n",
    "\n",
    "    agent_request: ReviewRequest | None = None\n",
    "\n",
    "\n",
    "class ReviewerWithHumanInTheLoop(Executor):\n",
    "    \"\"\"Reviewer that always escalates to a human manager.\"\"\"\n",
    "\n",
    "    def __init__(self, worker_id: str, request_info_id: str, reviewer_id: str | None = None) -> None:\n",
    "        unique_id = reviewer_id or f\"{worker_id}-reviewer\"\n",
    "        super().__init__(id=unique_id)\n",
    "        self._worker_id = worker_id\n",
    "        self._request_info_id = request_info_id\n",
    "\n",
    "    @handler\n",
    "    async def review(self, request: ReviewRequest, ctx: WorkflowContext[ReviewResponse | HumanReviewRequest]) -> None:\n",
    "        print(f\"Reviewer: Evaluating response for request {request.request_id[:8]}...\")\n",
    "        print(\"Reviewer: Escalating to human manager...\")\n",
    "        await ctx.send_message(HumanReviewRequest(agent_request=request), target_id=self._request_info_id)\n",
    "\n",
    "    @handler\n",
    "    async def accept_human_review(\n",
    "        self,\n",
    "        response: RequestResponse[HumanReviewRequest, ReviewResponse],\n",
    "        ctx: WorkflowContext[ReviewResponse],\n",
    "    ) -> None:\n",
    "        human_response = response.data\n",
    "        assert isinstance(human_response, ReviewResponse)\n",
    "        print(f\"Reviewer: Accepting human review for request {human_response.request_id[:8]}...\")\n",
    "        print(f\"Reviewer: Human feedback: {human_response.feedback}\")\n",
    "        print(f\"Reviewer: Human approved: {human_response.approved}\")\n",
    "        print(\"Reviewer: Forwarding human review back to worker...\")\n",
    "        await ctx.send_message(human_response, target_id=self._worker_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Wrap the workflow as an agent and drive the human loop\n",
    "The `main()` coroutine builds the workflow agent, sends an initial query, detects when human input is required, and feeds back a mocked approval. Replace the mock with real UI input in your app.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main() -> None:\n",
    "    print(\"Starting Workflow Agent with Human-in-the-Loop Demo\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Create executors for the workflow.\n",
    "    print(\"Creating chat client and executors...\")\n",
    "    mini_chat_client = OpenAIChatClient(model_id=\"gpt-4.1-nano\")\n",
    "    worker = Worker(id=\"sub-worker\", chat_client=mini_chat_client)\n",
    "    request_info_executor = RequestInfoExecutor(id=\"request_info\")\n",
    "    reviewer = ReviewerWithHumanInTheLoop(worker_id=worker.id, request_info_id=request_info_executor.id)\n",
    "\n",
    "    print(\"Building workflow with Worker \u2194 Reviewer cycle...\")\n",
    "    # Build a workflow with bidirectional communication between Worker and Reviewer,\n",
    "    # and escalation paths for human review.\n",
    "    agent = (\n",
    "        WorkflowBuilder()\n",
    "        .add_edge(worker, reviewer)  # Worker sends requests to Reviewer\n",
    "        .add_edge(reviewer, worker)  # Reviewer sends feedback to Worker\n",
    "        .add_edge(reviewer, request_info_executor)  # Reviewer requests human input\n",
    "        .add_edge(request_info_executor, reviewer)  # Human input forwarded back to Reviewer\n",
    "        .set_start_executor(worker)\n",
    "        .build()\n",
    "        .as_agent()  # Convert workflow into an agent interface\n",
    "    )\n",
    "\n",
    "    print(\"Running workflow agent with user query...\")\n",
    "    print(\"Query: 'Write code for parallel reading 1 million files on disk and write to a sorted output file.'\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # Run the agent with an initial query.\n",
    "    response = await agent.run(\n",
    "        \"Write code for parallel reading 1 million Files on disk and write to a sorted output file.\"\n",
    "    )\n",
    "\n",
    "    # Locate the human review function call in the response messages.\n",
    "    human_review_function_call: FunctionCallContent | None = None\n",
    "    for message in response.messages:\n",
    "        for content in message.contents:\n",
    "            if isinstance(content, FunctionCallContent) and content.name == WorkflowAgent.REQUEST_INFO_FUNCTION_NAME:\n",
    "                human_review_function_call = content\n",
    "\n",
    "    # Handle the human review if required.\n",
    "    if human_review_function_call:\n",
    "        # Parse the human review request arguments.\n",
    "        human_request_args = human_review_function_call.arguments\n",
    "        if isinstance(human_request_args, str):\n",
    "            request: WorkflowAgent.RequestInfoFunctionArgs = WorkflowAgent.RequestInfoFunctionArgs.from_json(\n",
    "                human_request_args\n",
    "            )\n",
    "        elif isinstance(human_request_args, Mapping):\n",
    "            request = WorkflowAgent.RequestInfoFunctionArgs.from_dict(dict(human_request_args))\n",
    "        else:\n",
    "            raise TypeError(\"Unexpected argument type for human review function call.\")\n",
    "\n",
    "        request_payload_obj: Any = request.data\n",
    "        if not isinstance(request_payload_obj, Mapping):\n",
    "            raise ValueError(\"Human review request payload must be a mapping.\")\n",
    "        request_payload = cast(Mapping[str, Any], request_payload_obj)\n",
    "\n",
    "        agent_request_obj = request_payload.get(\"agent_request\")\n",
    "        if not isinstance(agent_request_obj, Mapping):\n",
    "            raise ValueError(\"Human review request must include agent_request mapping data.\")\n",
    "        agent_request_data = cast(Mapping[str, Any], agent_request_obj)\n",
    "\n",
    "        request_id_obj = agent_request_data.get(\"request_id\")\n",
    "        if not isinstance(request_id_obj, str):\n",
    "            raise ValueError(\"Human review request_id must be a string.\")\n",
    "        request_id_value = request_id_obj\n",
    "\n",
    "        # Mock a human response approval for demonstration purposes.\n",
    "        human_response = ReviewResponse(request_id=request_id_value, feedback=\"Approved\", approved=True)\n",
    "\n",
    "        # Create the function call result object to send back to the agent.\n",
    "        human_review_function_result = FunctionResultContent(\n",
    "            call_id=human_review_function_call.call_id,\n",
    "            result=human_response,\n",
    "        )\n",
    "        # Send the human review result back to the agent.\n",
    "        response = await agent.run(ChatMessage(role=Role.TOOL, contents=[human_review_function_result]))\n",
    "        print(f\"\ud83d\udce4 Agent Response: {response.messages[-1].text}\")\n",
    "\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Workflow completed!\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step ??: Try it yourself\n",
    "Use the helper below. In notebooks it awaits `main()` on the active loop; in scripts it falls back to `asyncio.run(main())`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "# Helper for notebooks vs. scripts\n",
    "loop = asyncio.get_event_loop()\n",
    "if loop.is_running():\n",
    "    # Jupyter/VS Code notebooks already have an event loop, so await directly.\n",
    "    await main()\n",
    "else:\n",
    "    asyncio.run(main())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
