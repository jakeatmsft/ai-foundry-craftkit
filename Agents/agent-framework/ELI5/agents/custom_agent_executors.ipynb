{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# custom_agent_executors.py - ELI5 Walkthrough\n",
    "This notebook expands `python/samples/getting_started/workflows/agents/custom_agent_executors.py` with diagrams and commentary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big Picture\n",
    "Wrap two Azure OpenAI agents inside custom executors: the Writer produces messages, the Reviewer critiques them, and the final text becomes the workflow output.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Ingredients\n",
    "- `Executor` subclasses own an agent client and expose typed handlers.\n",
    "- `WorkflowContext` carries both downstream messages and workflow outputs.\n",
    "- The fluent `WorkflowBuilder` stitches the Writer and Reviewer into a tiny pipeline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow Diagram\n",
    "```mermaid\n",
    "flowchart LR\n",
    "    Start([\"User Prompt\"]) --> Writer[[Writer Executor + Agent]]\n",
    "    Writer --> Reviewer[[Reviewer Executor + Agent]]\n",
    "    Reviewer --> Output([\"Workflow Output\"])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Imports and scenario overview\n",
    "Load Agent Framework dependencies, configure Azure credentials, and keep the docstring describing why we build custom executors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Microsoft. All rights reserved.\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import asyncio\n",
    "\n",
    "from agent_framework import (\n",
    "    ChatAgent,\n",
    "    ChatMessage,\n",
    "    Executor,\n",
    "    WorkflowBuilder,\n",
    "    WorkflowContext,\n",
    "    handler,\n",
    ")\n",
    "from agent_framework.azure import AzureOpenAIChatClient\n",
    "from azure.identity import AzureCliCredential\n",
    "\n",
    "\"\"\"\n",
    "Step 2: Agents in a Workflow non-streaming\n",
    "\n",
    "This sample uses two custom executors. A Writer agent creates or edits content,\n",
    "then hands the conversation to a Reviewer agent which evaluates and finalizes the result.\n",
    "\n",
    "Purpose:\n",
    "Show how to wrap chat agents created by AzureOpenAIChatClient inside workflow executors. Demonstrate the @handler pattern\n",
    "with typed inputs and typed WorkflowContext[T] outputs, connect executors with the fluent WorkflowBuilder, and finish\n",
    "by yielding outputs from the terminal node.\n",
    "\n",
    "Prerequisites:\n",
    "- Azure OpenAI configured for AzureOpenAIChatClient with required environment variables.\n",
    "- Authentication via azure-identity. Use AzureCliCredential and run az login before executing the sample.\n",
    "- Basic familiarity with WorkflowBuilder, executors, edges, events, and streaming or non streaming runs.\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Writer executor wraps the authoring agent\n",
    "The Writer accepts a `ChatMessage`, runs its agent, and forwards the expanded transcript to the next node.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Writer(Executor):\n",
    "    \"\"\"Custom executor that owns a domain specific agent responsible for generating content.\n",
    "\n",
    "    This class demonstrates:\n",
    "    - Attaching a ChatAgent to an Executor so it participates as a node in a workflow.\n",
    "    - Using a @handler method to accept a typed input and forward a typed output via ctx.send_message.\n",
    "    \"\"\"\n",
    "\n",
    "    agent: ChatAgent\n",
    "\n",
    "    def __init__(self, chat_client: AzureOpenAIChatClient, id: str = \"writer\"):\n",
    "        # Create a domain specific agent using your configured AzureOpenAIChatClient.\n",
    "        self.agent = chat_client.create_agent(\n",
    "            instructions=(\n",
    "                \"You are an excellent content writer. You create new content and edit contents based on the feedback.\"\n",
    "            ),\n",
    "        )\n",
    "        # Associate the agent with this executor node. The base Executor stores it on self.agent.\n",
    "        super().__init__(id=id)\n",
    "\n",
    "    @handler\n",
    "    async def handle(self, message: ChatMessage, ctx: WorkflowContext[list[ChatMessage], str]) -> None:\n",
    "        \"\"\"Generate content using the agent and forward the updated conversation.\n",
    "\n",
    "        Contract for this handler:\n",
    "        - message is the inbound user ChatMessage.\n",
    "        - ctx is a WorkflowContext that expects a list[ChatMessage] to be sent downstream.\n",
    "\n",
    "        Pattern shown here:\n",
    "        1) Seed the conversation with the inbound message.\n",
    "        2) Run the attached agent to produce assistant messages.\n",
    "        3) Forward the cumulative messages to the next executor with ctx.send_message.\n",
    "        \"\"\"\n",
    "        # Start the conversation with the incoming user message.\n",
    "        messages: list[ChatMessage] = [message]\n",
    "        # Run the agent and extend the conversation with the agent's messages.\n",
    "        response = await self.agent.run(messages)\n",
    "        messages.extend(response.messages)\n",
    "        # Forward the accumulated messages to the next executor in the workflow.\n",
    "        await ctx.send_message(messages)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Reviewer executor finalizes the response\n",
    "The Reviewer consumes the transcript, calls its agent, and yields the final text via `ctx.yield_output`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reviewer(Executor):\n",
    "    \"\"\"Custom executor that owns a review agent and completes the workflow.\n",
    "\n",
    "    This class demonstrates:\n",
    "    - Consuming a typed payload produced upstream.\n",
    "    - Yielding the final text outcome to complete the workflow.\n",
    "    \"\"\"\n",
    "\n",
    "    agent: ChatAgent\n",
    "\n",
    "    def __init__(self, chat_client: AzureOpenAIChatClient, id: str = \"reviewer\"):\n",
    "        # Create a domain specific agent that evaluates and refines content.\n",
    "        self.agent = chat_client.create_agent(\n",
    "            instructions=(\n",
    "                \"You are an excellent content reviewer. You review the content and provide feedback to the writer.\"\n",
    "            ),\n",
    "        )\n",
    "        super().__init__(id=id)\n",
    "\n",
    "    @handler\n",
    "    async def handle(self, messages: list[ChatMessage], ctx: WorkflowContext[list[ChatMessage], str]) -> None:\n",
    "        \"\"\"Review the full conversation transcript and complete with a final string.\n",
    "\n",
    "        This node consumes all messages so far. It uses its agent to produce the final text,\n",
    "        then signals completion by yielding the output.\n",
    "        \"\"\"\n",
    "        response = await self.agent.run(messages)\n",
    "        await ctx.yield_output(response.text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Build and run the workflow\n",
    "`main()` constructs the pipeline, passes a sample prompt, and prints the resulting output string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    \"\"\"Build and run a simple two node agent workflow: Writer then Reviewer.\"\"\"\n",
    "    # Create the Azure chat client. AzureCliCredential uses your current az login.\n",
    "    chat_client = AzureOpenAIChatClient(credential=AzureCliCredential())\n",
    "\n",
    "    # Instantiate the two agent backed executors.\n",
    "    writer = Writer(chat_client)\n",
    "    reviewer = Reviewer(chat_client)\n",
    "\n",
    "    # Build the workflow using the fluent builder.\n",
    "    # Set the start node and connect an edge from writer to reviewer.\n",
    "    workflow = WorkflowBuilder().set_start_executor(writer).add_edge(writer, reviewer).build()\n",
    "\n",
    "    # Run the workflow with the user's initial message.\n",
    "    # For foundational clarity, use run (non streaming) and print the workflow output.\n",
    "    events = await workflow.run(\n",
    "        ChatMessage(role=\"user\", text=\"Create a slogan for a new electric SUV that is affordable and fun to drive.\")\n",
    "    )\n",
    "    # The terminal node yields output; print its contents.\n",
    "    outputs = events.get_outputs()\n",
    "    if outputs:\n",
    "        print(outputs[-1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Try it yourself\n",
    "Use the helper below. In notebooks it awaits `main()` on the active loop; in scripts it falls back to `asyncio.run(main())`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "# Helper for notebooks vs. scripts\n",
    "loop = asyncio.get_event_loop()\n",
    "if loop.is_running():\n",
    "    # Jupyter/VS Code notebooks already have an event loop, so await directly.\n",
    "    await main()\n",
    "else:\n",
    "    asyncio.run(main())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
