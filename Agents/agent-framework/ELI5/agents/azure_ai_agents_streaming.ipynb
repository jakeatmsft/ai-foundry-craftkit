{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# azure_ai_agents_streaming.py - ELI5 Walkthrough\n",
    "This notebook gives a super-friendly tour of `python/samples/getting_started/workflows/agents/azure_ai_agents_streaming.py` from the Agent Framework samples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big Picture\n",
    "Imagine two coworkers: a Writer who drafts marketing slogans and a Reviewer who reacts in real time. ",
    "This workflow wires both Azure AI agents together and streams their thoughts token by token so you can watch the creative back-and-forth live.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Ingredients\n",
    "- **AzureAIAgentClient** - spins up hosted Azure AI agents with instructions.\n",
    "- **AsyncExitStack** - keeps async context managers tidy and closes everything once we're done.\n",
    "- **WorkflowBuilder.add_agent** - drops ready-to-use agent executors into the workflow graph.\n",
    "- **run_stream() + AgentRunUpdateEvent** - streams incremental text chunks you can print as they arrive.\n",
    "- **WorkflowOutputEvent** - emits the reviewer's final verdict as the workflow output.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow Diagram\n",
    "```mermaid\n",
    "flowchart LR\n",
    "    Start([\"Start Prompt\"]) --> Writer[[Writer agent]]\n",
    "    Writer --> Reviewer[[Reviewer agent]]\n",
    "    Reviewer --> Output([\"Workflow Output\"])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from collections.abc import Awaitable, Callable\n",
    "from contextlib import AsyncExitStack\n",
    "from typing import Any, Optional\n",
    "\n",
    "from agent_framework import AgentRunUpdateEvent, WorkflowBuilder, WorkflowOutputEvent\n",
    "from agent_framework.azure import AzureAIAgentClient\n",
    "from azure.identity.aio import AzureCliCredential\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "async def create_azure_ai_agent() -> tuple[Callable[..., Awaitable[Any]], Callable[[], Awaitable[None]]]:\n",
    "    \"\"\"Helper method to create an Azure AI agent factory and a close function.\"\"\"\n",
    "    stack = AsyncExitStack()\n",
    "    cred = await stack.enter_async_context(AzureCliCredential())\n",
    "    client = await stack.enter_async_context(AzureAIAgentClient(async_credential=cred))\n",
    "\n",
    "    async def agent(**kwargs: Any) -> Any:\n",
    "        return await stack.enter_async_context(client.create_agent(**kwargs))\n",
    "\n",
    "    async def close() -> None:\n",
    "        await stack.aclose()\n",
    "\n",
    "    return agent, close\n",
    "\n",
    "\n",
    "async def main() -> None:\n",
    "    agent, close = await create_azure_ai_agent()\n",
    "    try:\n",
    "        writer = await agent(\n",
    "            name=\"Writer\",\n",
    "            instructions=(\n",
    "                \"You are an excellent content writer. You create new content and edit contents based on the feedback.\"\n",
    "            ),\n",
    "        )\n",
    "        reviewer = await agent(\n",
    "            name=\"Reviewer\",\n",
    "            instructions=(\n",
    "                \"You are an excellent content reviewer. \"\n",
    "                \"Provide actionable feedback to the writer about the provided content. \"\n",
    "                \"Provide the feedback in the most concise manner possible.\"\n",
    "            ),\n",
    "        )\n",
    "        workflow = (\n",
    "            WorkflowBuilder()\n",
    "            .add_agent(writer, id=\"Writer\")\n",
    "            .add_agent(reviewer, id=\"Reviewer\", output_response=True)\n",
    "            .set_start_executor(writer)\n",
    "            .add_edge(writer, reviewer)\n",
    "            .build()\n",
    "        )\n",
    "\n",
    "        last_executor_id: Optional[str] = None\n",
    "        events = workflow.run_stream(\"Create a slogan for a new electric SUV that is affordable and fun to drive.\")\n",
    "        async for event in events:\n",
    "            if isinstance(event, AgentRunUpdateEvent):\n",
    "                eid = event.executor_id\n",
    "                if eid != last_executor_id:\n",
    "                    if last_executor_id is not None:\n",
    "                        print()\n",
    "                    print(f\"{eid}:\", end=\" \", flush=True)\n",
    "                    last_executor_id = eid\n",
    "                print(event.data, end=\"\", flush=True)\n",
    "            elif isinstance(event, WorkflowOutputEvent):\n",
    "                print(\"\\n===== Final output =====\")\n",
    "                print(event.data)\n",
    "    finally:\n",
    "        await close()\n",
    "\n",
    "\n",
    "# main() is left defined but not executed so you can control when to run the Azure workflow.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What the script does\n",
    "This sample links a writer and reviewer Azure AI agent with streaming updates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the agents safely\n",
    "create_azure_ai_agent() hides the boilerplate for spinning up Azure CLI auth and the Azure AI agent client. ",
    "It returns a factory that the workflow uses to create agents on demand, plus a close() helper so everything shuts down cleanly.\n",
    "\n",
    "The async exit stack tracks every context manager so a single await close() unwinds credentials, clients, and agents even if an error appears mid-run.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import inspect\n",
    "print(inspect.getsource(create_azure_ai_agent))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the workflow pipeline\n",
    "The workflow graph is tiny on purpose:\n",
    "1. Kick off with the Writer agent (set as the start executor).\n",
    "2. Pipe whatever the Writer produces straight into the Reviewer using .add_edge(writer, reviewer).\n",
    "3. Mark the Reviewer with output_response=True so its final AgentRunResponse becomes a workflow output.\n",
    "\n",
    "Adding real agent objects via add_agent means the framework handles run vs. stream wiring with no extra glue code from you.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "workflow_outline = [\n",
    "    ('start', 'Writer', 'prompt -> draft'),\n",
    "    ('Writer', 'Reviewer', 'stream drafts token-by-token'),\n",
    "    ('Reviewer', 'workflow_output', 'final critique'),\n",
    "]\n",
    "workflow_outline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming events in action\n",
    "When you call workflow.run_stream(...), the engine yields two kinds of events that this sample prints:\n",
    "- AgentRunUpdateEvent - incremental text chunks produced by the current agent.\n",
    "- WorkflowOutputEvent - the final answer that the Reviewer yields once the run is done.\n",
    "\n",
    "The loop keeps track of which executor is currently speaking so the console output stays readable.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from agent_framework import AgentRunResponseUpdate\n",
    "\n",
    "mock_stream = [\n",
    "    AgentRunUpdateEvent('Writer', AgentRunResponseUpdate(text='Drafting: Electric thrills for everyone.')),\n",
    "    AgentRunUpdateEvent('Writer', AgentRunResponseUpdate(text=' Embrace the spark.')),\n",
    "    AgentRunUpdateEvent('Reviewer', AgentRunResponseUpdate(text='Suggestion: Mention affordability sooner.')),\n",
    "    WorkflowOutputEvent('Final tweak: Electric fun you can afford.', source_executor_id='Reviewer'),\n",
    "]\n",
    "\n",
    "last_executor = None\n",
    "for event in mock_stream:\n",
    "    if isinstance(event, AgentRunUpdateEvent):\n",
    "        if event.executor_id != last_executor:\n",
    "            if last_executor is not None:\n",
    "                print()\n",
    "            print(\"{}:\".format(event.executor_id), end=\" \", flush=True)\n",
    "            last_executor = event.executor_id\n",
    "        print(event.data.text, end=\"\", flush=True)\n",
    "    elif isinstance(event, WorkflowOutputEvent):\n",
    "        print(\"\\n===== Final output =====\")\n",
    "        print(event.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways\n",
    "- AsyncExitStack makes async resource cleanup painless even with multiple agents.\n",
    "- add_agent(..., output_response=True) is how you surface the final reviewer message as workflow output.\n",
    "- Streaming events let you build live dashboards or logs without waiting for the run to finish.\n",
    "- You can scale the pattern with more agents (editor, fact-checker, translator) by chaining more add_agent and add_edge calls.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "# Helper for notebooks vs. scripts\n",
    "loop = asyncio.get_event_loop()\n",
    "if loop.is_running():\n",
    "    # Jupyter/VS Code notebooks already have an event loop, so await directly.\n",
    "    await main()\n",
    "else:\n",
    "    asyncio.run(main())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
